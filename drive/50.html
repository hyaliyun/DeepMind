<!DOCTYPE html>
<html lang="zh" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>DeepMind</title>
    <meta name="description" content="DeepMind">
    <meta name="generator" content="VitePress v1.5.0">
    <link rel="preload stylesheet" href="/assets/style.DUp0Lj6k.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.7uGsmnbX.js"></script>
    <link rel="modulepreload" href="/assets/chunks/theme.QB-wH4Se.js">
    <link rel="modulepreload" href="/assets/chunks/framework.B1z0IdBH.js">
    <link rel="modulepreload" href="/assets/drive_50.md.CTkugyYO.lean.js">
    <link rel="icon" href="/logo.svg">
    <link rel="icon" type="image/svg+xml" href="/images/logo.png">
    <meta name="theme-color" content="#3c8772">
    <meta property="og:url" content="https://www.252x.com">
    <meta property="og:type" content="website">
    <meta property="og:title" content="DeepMind">
    <meta property="og:description" content="DeepMind">
    <meta property="og:image" content="/images/logo.png">
    <meta name="twitter:site" content="@book">
    <meta name="twitter:card" content="summary">
    <link rel="preconnect" href="https://f.543x.com">
    <script>(()=>{const e=(o,r,t=!1)=>{const s=localStorage.getItem(o);(s?s!=="false":t)&&document.documentElement.classList.add(r)};e("vue-docs-prefer-composition","prefer-composition",!0),e("vue-docs-prefer-sfc","prefer-sfc",!0),window.__VUE_BANNER_ID__="vt2024_1",e(`vue-docs-banner-${__VUE_BANNER_ID__}`,"banner-dismissed")})();</script>
    <script>location.search.includes("?uwu")&&document.documentElement.classList.add("uwu");</script>
    <script src="https://cdn.usefathom.com/script.js" data-site="XNOLWPLB" data-spa="auto" defer></script>
    <script src="https://vueschool.io/banner.js?affiliate=book&amp;type=top" async></script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
  </head>
  <body>
    <div id="app"><div class="VPApp" data-v-e4982c5a><!--[--><span tabindex="-1" data-v-ebeb79d9></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-ebeb79d9>Skip to content</a><!--]--><!----><!--[--><div class="banner" data-v-8f28d446><p class="vt-banner-text" data-v-8f28d446><span class="vt-text-primary" data-v-8f28d446>VueConf Toronto</span><span class="vt-tagline" data-v-8f28d446> - Join the premier TypeScript conference</span><a target="_blank" class="vt-primary-action" href="https://www.543x.com" data-v-8f28d446> Register </a></p><button data-v-8f28d446><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="close" data-v-8f28d446><path d="M18.9,10.9h-6v-6c0-0.6-0.4-1-1-1s-1,0.4-1,1v6h-6c-0.6,0-1,0.4-1,1s0.4,1,1,1h6v6c0,0.6,0.4,1,1,1s1-0.4,1-1v-6h6c0.6,0,1-0.4,1-1S19.5,10.9,18.9,10.9z"></path></svg></button><p class="vt-banner-text vt-coupon" data-v-8f28d446><span class="vt-text-primary" data-v-8f28d446>www</span> 543x <span class="vt-text-primary" data-v-8f28d446>.com</span></p></div><!--]--><header class="VPNav nav-bar stick" data-v-e4982c5a data-v-9cbed0dc><div class="VPNavBar" data-v-9cbed0dc data-v-78ea45ed><div class="container" data-v-78ea45ed><a class="VPNavBarTitle" href="/" data-v-78ea45ed data-v-4b84c549><!--[--><svg class="logo" viewBox="0 0 128 128" width="24" height="24" data-v-4b84c549><path fill="#42b883" d="M78.8,10L64,35.4L49.2,10H0l64,110l64-110C128,10,78.8,10,78.8,10z" data-v-4b84c549></path><path fill="#35495e" d="M78.8,10L64,35.4L49.2,10H25.6L64,76l38.4-66H78.8z" data-v-4b84c549></path></svg><span class="text" data-v-4b84c549>Vue.js</span><!--]--></a><div class="content" data-v-78ea45ed><div class="VPNavBarSearch search" data-v-78ea45ed><!----><div id="docsearch"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><!----></button></div></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-78ea45ed data-v-2cfd1945><span id="main-nav-aria-label" class="visually-hidden" data-v-2cfd1945>Main Navigation</span><!--[--><!--[--><div class="vt-flyout VPNavBarMenuGroup active" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">data <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/drive/1.html"><!--[-->data1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/2.html"><!--[-->data2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/3.html"><!--[-->data3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/4.html"><!--[-->data4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/5.html"><!--[-->data5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/6.html"><!--[-->data6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/7.html"><!--[-->data7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/8.html"><!--[-->data8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/9.html"><!--[-->data9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/10.html"><!--[-->data10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/11.html"><!--[-->data11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/12.html"><!--[-->data12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/13.html"><!--[-->data13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/14.html"><!--[-->data14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/15.html"><!--[-->data15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/16.html"><!--[-->data16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/17.html"><!--[-->data17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/18.html"><!--[-->data18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/19.html"><!--[-->data19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/20.html"><!--[-->data20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/21.html"><!--[-->data21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/22.html"><!--[-->data22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/23.html"><!--[-->data23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/24.html"><!--[-->data24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/25.html"><!--[-->data25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/26.html"><!--[-->data26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/27.html"><!--[-->data27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/28.html"><!--[-->data28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/29.html"><!--[-->data29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/30.html"><!--[-->data30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/31.html"><!--[-->data31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/32.html"><!--[-->data32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/33.html"><!--[-->data33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/34.html"><!--[-->data34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/35.html"><!--[-->data35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/36.html"><!--[-->data36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/37.html"><!--[-->data37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/38.html"><!--[-->data38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/39.html"><!--[-->data39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/40.html"><!--[-->data40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/41.html"><!--[-->data41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/42.html"><!--[-->data42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/43.html"><!--[-->data43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/44.html"><!--[-->data44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/45.html"><!--[-->data45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/46.html"><!--[-->data46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/47.html"><!--[-->data47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/48.html"><!--[-->data48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/49.html"><!--[-->data49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/50.html"><!--[-->data50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/51.html"><!--[-->data51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/52.html"><!--[-->data52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/53.html"><!--[-->data53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/54.html"><!--[-->data54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/55.html"><!--[-->data55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/56.html"><!--[-->data56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/57.html"><!--[-->data57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/58.html"><!--[-->data58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/59.html"><!--[-->data59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/60.html"><!--[-->data60<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">grok <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/grok/1.html"><!--[-->grok1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/2.html"><!--[-->grok2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/3.html"><!--[-->grok3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/4.html"><!--[-->grok4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/5.html"><!--[-->grok5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/6.html"><!--[-->grok6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/7.html"><!--[-->grok7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/8.html"><!--[-->grok8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/9.html"><!--[-->grok9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/10.html"><!--[-->grok10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/11.html"><!--[-->grok11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/12.html"><!--[-->grok12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/13.html"><!--[-->grok13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/14.html"><!--[-->grok14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/15.html"><!--[-->grok15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/16.html"><!--[-->grok16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/17.html"><!--[-->grok17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/18.html"><!--[-->grok18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/19.html"><!--[-->grok19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/20.html"><!--[-->grok20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/21.html"><!--[-->grok21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/22.html"><!--[-->grok22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/23.html"><!--[-->grok23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/24.html"><!--[-->grok24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/25.html"><!--[-->grok25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/26.html"><!--[-->grok26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/27.html"><!--[-->grok27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/28.html"><!--[-->grok28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/29.html"><!--[-->grok29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/30.html"><!--[-->grok30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/31.html"><!--[-->grok31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/32.html"><!--[-->grok32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/33.html"><!--[-->grok33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/34.html"><!--[-->grok34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/35.html"><!--[-->grok35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/36.html"><!--[-->grok36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/37.html"><!--[-->grok37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/38.html"><!--[-->grok38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/39.html"><!--[-->grok39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/40.html"><!--[-->grok40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/41.html"><!--[-->grok41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/42.html"><!--[-->grok42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/43.html"><!--[-->grok43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/44.html"><!--[-->grok44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/45.html"><!--[-->grok45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/46.html"><!--[-->grok46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/47.html"><!--[-->grok47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/48.html"><!--[-->grok48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/49.html"><!--[-->grok49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/50.html"><!--[-->grok50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/51.html"><!--[-->grok51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/52.html"><!--[-->grok52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/53.html"><!--[-->grok53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/54.html"><!--[-->grok54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/55.html"><!--[-->grok55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/56.html"><!--[-->grok56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/57.html"><!--[-->grok57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/58.html"><!--[-->grok58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/59.html"><!--[-->grok59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/60.html"><!--[-->grok60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/61.html"><!--[-->grok61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/62.html"><!--[-->grok62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/63.html"><!--[-->grok63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/64.html"><!--[-->grok64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/65.html"><!--[-->grok65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/66.html"><!--[-->grok66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/67.html"><!--[-->grok67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/grok/68.html"><!--[-->grok68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">wiki <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/guide/1.html"><!--[-->wiki1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/2.html"><!--[-->wiki2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/3.html"><!--[-->wiki3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/4.html"><!--[-->wiki4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/5.html"><!--[-->wiki5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/6.html"><!--[-->wiki6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/7.html"><!--[-->wiki7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/8.html"><!--[-->wiki8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/9.html"><!--[-->wiki9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/10.html"><!--[-->wiki10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/11.html"><!--[-->wiki11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/12.html"><!--[-->wiki12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/13.html"><!--[-->wiki13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/14.html"><!--[-->wiki14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/15.html"><!--[-->wiki15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/16.html"><!--[-->wiki16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/17.html"><!--[-->wiki17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/18.html"><!--[-->wiki18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/19.html"><!--[-->wiki19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/20.html"><!--[-->wiki20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/21.html"><!--[-->wiki21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/22.html"><!--[-->wiki22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/23.html"><!--[-->wiki23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/24.html"><!--[-->wiki24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/25.html"><!--[-->wiki25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/26.html"><!--[-->wiki26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/27.html"><!--[-->wiki27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/28.html"><!--[-->wiki28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/29.html"><!--[-->wiki29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/30.html"><!--[-->wiki30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/31.html"><!--[-->wiki31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/32.html"><!--[-->wiki32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/33.html"><!--[-->wiki33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/34.html"><!--[-->wiki34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/35.html"><!--[-->wiki35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/36.html"><!--[-->wiki36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/37.html"><!--[-->wiki37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/38.html"><!--[-->wiki38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/39.html"><!--[-->wiki39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/40.html"><!--[-->wiki40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/41.html"><!--[-->wiki41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/42.html"><!--[-->wiki42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/43.html"><!--[-->wiki43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/44.html"><!--[-->wiki44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/45.html"><!--[-->wiki45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/46.html"><!--[-->wiki46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/47.html"><!--[-->wiki47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/48.html"><!--[-->wiki48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/49.html"><!--[-->wiki49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/50.html"><!--[-->wiki50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/51.html"><!--[-->wiki51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/52.html"><!--[-->wiki52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/53.html"><!--[-->wiki53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/54.html"><!--[-->wiki54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/55.html"><!--[-->wiki55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/56.html"><!--[-->wiki56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/57.html"><!--[-->wiki57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/58.html"><!--[-->wiki58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/59.html"><!--[-->wiki59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/60.html"><!--[-->wiki60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/61.html"><!--[-->wiki61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/62.html"><!--[-->wiki62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/63.html"><!--[-->wiki63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/64.html"><!--[-->wiki64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/65.html"><!--[-->wiki65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/66.html"><!--[-->wiki66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/67.html"><!--[-->wiki67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/guide/68.html"><!--[-->wiki68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">deep <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/1.html"><!--[-->deep1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/2.html"><!--[-->deep2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/3.html"><!--[-->deep3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/4.html"><!--[-->deep4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/5.html"><!--[-->deep5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/6.html"><!--[-->deep6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/7.html"><!--[-->deep7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/8.html"><!--[-->deep8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/9.html"><!--[-->deep9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/10.html"><!--[-->deep10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/11.html"><!--[-->deep11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/12.html"><!--[-->deep12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/13.html"><!--[-->deep13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/14.html"><!--[-->deep14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/15.html"><!--[-->deep15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/16.html"><!--[-->deep16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/17.html"><!--[-->deep17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/18.html"><!--[-->deep18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/19.html"><!--[-->deep19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/20.html"><!--[-->deep20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/21.html"><!--[-->deep21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/22.html"><!--[-->deep22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/23.html"><!--[-->deep23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/24.html"><!--[-->deep24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/25.html"><!--[-->deep25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/26.html"><!--[-->deep26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/27.html"><!--[-->deep27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/28.html"><!--[-->deep28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/29.html"><!--[-->deep29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/30.html"><!--[-->deep30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/31.html"><!--[-->deep31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/32.html"><!--[-->deep32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/33.html"><!--[-->deep33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/34.html"><!--[-->deep34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/35.html"><!--[-->deep35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/36.html"><!--[-->deep36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/37.html"><!--[-->deep37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/38.html"><!--[-->deep38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/39.html"><!--[-->deep39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/40.html"><!--[-->deep40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/41.html"><!--[-->deep41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/42.html"><!--[-->deep42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/43.html"><!--[-->deep43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/44.html"><!--[-->deep44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/45.html"><!--[-->deep45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/46.html"><!--[-->deep46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/47.html"><!--[-->deep47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/48.html"><!--[-->deep48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/49.html"><!--[-->deep49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/50.html"><!--[-->deep50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/51.html"><!--[-->deep51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/52.html"><!--[-->deep52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/53.html"><!--[-->deep53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/54.html"><!--[-->deep54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/55.html"><!--[-->deep55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/56.html"><!--[-->deep56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/57.html"><!--[-->deep57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/58.html"><!--[-->deep58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/59.html"><!--[-->deep59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/60.html"><!--[-->deep60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/61.html"><!--[-->deep61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/62.html"><!--[-->deep62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/63.html"><!--[-->deep63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/64.html"><!--[-->deep64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/65.html"><!--[-->deep65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/66.html"><!--[-->deep66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/67.html"><!--[-->deep67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/deepseek/68.html"><!--[-->deep68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">quotes <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/1.html"><!--[-->quotes1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/2.html"><!--[-->quotes2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/3.html"><!--[-->quotes3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/4.html"><!--[-->quotes4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/5.html"><!--[-->quotes5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/6.html"><!--[-->quotes6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/7.html"><!--[-->quotes7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/8.html"><!--[-->quotes8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/9.html"><!--[-->quotes9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/10.html"><!--[-->quotes10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/11.html"><!--[-->quotes11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/12.html"><!--[-->quotes12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/13.html"><!--[-->quotes13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/14.html"><!--[-->quotes14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/15.html"><!--[-->quotes15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/16.html"><!--[-->quotes16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/17.html"><!--[-->quotes17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/18.html"><!--[-->quotes18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/19.html"><!--[-->quotes19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/20.html"><!--[-->quotes20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/21.html"><!--[-->quotes21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/22.html"><!--[-->quotes22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/23.html"><!--[-->quotes23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/24.html"><!--[-->quotes24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/25.html"><!--[-->quotes25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/26.html"><!--[-->quotes26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/27.html"><!--[-->quotes27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/28.html"><!--[-->quotes28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/29.html"><!--[-->quotes29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/30.html"><!--[-->quotes30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/31.html"><!--[-->quotes31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/32.html"><!--[-->quotes32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/33.html"><!--[-->quotes33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/34.html"><!--[-->quotes34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/35.html"><!--[-->quotes35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/36.html"><!--[-->quotes36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/37.html"><!--[-->quotes37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/38.html"><!--[-->quotes38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/39.html"><!--[-->quotes39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/40.html"><!--[-->quotes40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/41.html"><!--[-->quotes41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/42.html"><!--[-->quotes42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/43.html"><!--[-->quotes43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/44.html"><!--[-->quotes44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/45.html"><!--[-->quotes45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/46.html"><!--[-->quotes46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/47.html"><!--[-->quotes47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/48.html"><!--[-->quotes48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/49.html"><!--[-->quotes49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/50.html"><!--[-->quotes50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/51.html"><!--[-->quotes51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/52.html"><!--[-->quotes52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/53.html"><!--[-->quotes53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/54.html"><!--[-->quotes54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/55.html"><!--[-->quotes55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/56.html"><!--[-->quotes56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/57.html"><!--[-->quotes57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/58.html"><!--[-->quotes58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/59.html"><!--[-->quotes59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/60.html"><!--[-->quotes60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/61.html"><!--[-->quotes61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/62.html"><!--[-->quotes62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/63.html"><!--[-->quotes63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/64.html"><!--[-->quotes64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/65.html"><!--[-->quotes65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/66.html"><!--[-->quotes66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/67.html"><!--[-->quotes67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/quotes/68.html"><!--[-->quotes68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">chatai <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/1.html"><!--[-->chatai1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/2.html"><!--[-->chatai2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/3.html"><!--[-->chatai3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/4.html"><!--[-->chatai4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/5.html"><!--[-->chatai5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/6.html"><!--[-->chatai6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/7.html"><!--[-->chatai7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/8.html"><!--[-->chatai8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/9.html"><!--[-->chatai9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/10.html"><!--[-->chatai10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/11.html"><!--[-->chatai11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/12.html"><!--[-->chatai12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/13.html"><!--[-->chatai13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/14.html"><!--[-->chatai14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/15.html"><!--[-->chatai15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/16.html"><!--[-->chatai16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/17.html"><!--[-->chatai17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/18.html"><!--[-->chatai18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/19.html"><!--[-->chatai19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/20.html"><!--[-->chatai20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/21.html"><!--[-->chatai21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/22.html"><!--[-->chatai22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/23.html"><!--[-->chatai23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/24.html"><!--[-->chatai24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/25.html"><!--[-->chatai25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/26.html"><!--[-->chatai26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/27.html"><!--[-->chatai27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/28.html"><!--[-->chatai28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/29.html"><!--[-->chatai29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/30.html"><!--[-->chatai30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/31.html"><!--[-->chatai31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/32.html"><!--[-->chatai32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/33.html"><!--[-->chatai33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/34.html"><!--[-->chatai34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/35.html"><!--[-->chatai35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/36.html"><!--[-->chatai36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/37.html"><!--[-->chatai37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/38.html"><!--[-->chatai38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/39.html"><!--[-->chatai39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/40.html"><!--[-->chatai40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/41.html"><!--[-->chatai41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/42.html"><!--[-->chatai42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/43.html"><!--[-->chatai43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/44.html"><!--[-->chatai44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/45.html"><!--[-->chatai45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/46.html"><!--[-->chatai46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/47.html"><!--[-->chatai47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/48.html"><!--[-->chatai48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/49.html"><!--[-->chatai49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/50.html"><!--[-->chatai50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/51.html"><!--[-->chatai51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/52.html"><!--[-->chatai52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/53.html"><!--[-->chatai53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/54.html"><!--[-->chatai54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/55.html"><!--[-->chatai55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/56.html"><!--[-->chatai56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/57.html"><!--[-->chatai57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/58.html"><!--[-->chatai58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/59.html"><!--[-->chatai59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/60.html"><!--[-->chatai60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/61.html"><!--[-->chatai61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/62.html"><!--[-->chatai62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/63.html"><!--[-->chatai63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/64.html"><!--[-->chatai64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/65.html"><!--[-->chatai65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/66.html"><!--[-->chatai66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/67.html"><!--[-->chatai67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/chatai/68.html"><!--[-->chatai68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">library <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/library/1.html"><!--[-->library1<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/2.html"><!--[-->library2<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/3.html"><!--[-->library3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/4.html"><!--[-->library4<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/5.html"><!--[-->library5<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/6.html"><!--[-->library6<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/7.html"><!--[-->library7<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/8.html"><!--[-->library8<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/9.html"><!--[-->library9<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/10.html"><!--[-->library10<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/11.html"><!--[-->library11<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/12.html"><!--[-->library12<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/13.html"><!--[-->library13<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/14.html"><!--[-->library14<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/15.html"><!--[-->library15<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/16.html"><!--[-->library16<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/17.html"><!--[-->library17<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/18.html"><!--[-->library18<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/19.html"><!--[-->library19<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/20.html"><!--[-->library20<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/21.html"><!--[-->library21<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/22.html"><!--[-->library22<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/23.html"><!--[-->library23<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/24.html"><!--[-->library24<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/25.html"><!--[-->library25<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/26.html"><!--[-->library26<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/27.html"><!--[-->library27<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/28.html"><!--[-->library28<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/29.html"><!--[-->library29<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/30.html"><!--[-->library30<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/31.html"><!--[-->library31<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/32.html"><!--[-->library32<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/33.html"><!--[-->library33<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/34.html"><!--[-->library34<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/35.html"><!--[-->library35<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/36.html"><!--[-->library36<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/37.html"><!--[-->library37<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/38.html"><!--[-->library38<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/39.html"><!--[-->library39<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/40.html"><!--[-->library40<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/41.html"><!--[-->library41<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/42.html"><!--[-->library42<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/43.html"><!--[-->library43<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/44.html"><!--[-->library44<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/45.html"><!--[-->library45<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/46.html"><!--[-->library46<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/47.html"><!--[-->library47<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/48.html"><!--[-->library48<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/49.html"><!--[-->library49<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/50.html"><!--[-->library50<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/51.html"><!--[-->library51<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/52.html"><!--[-->library52<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/53.html"><!--[-->library53<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/54.html"><!--[-->library54<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/55.html"><!--[-->library55<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/56.html"><!--[-->library56<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/57.html"><!--[-->library57<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/58.html"><!--[-->library58<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/59.html"><!--[-->library59<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/60.html"><!--[-->library60<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/61.html"><!--[-->library61<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/62.html"><!--[-->library62<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/63.html"><!--[-->library63<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/64.html"><!--[-->library64<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/65.html"><!--[-->library65<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/66.html"><!--[-->library66<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/67.html"><!--[-->library67<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/library/68.html"><!--[-->library68<!--]--><!----><!----></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">ecosystem <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><div class="vt-menu-group"><p class="vt-menu-group-title">website</p><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/partners/"><!--[-->partners<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/ecosystem/themes.html"><!--[-->website<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/ecosystem/newsletters.html"><!--[-->deepseekletters<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/ecosystem/navigation.html"><!--[-->AI Navigation<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/ecosystem/DeepSeek.html"><!--[-->DeepSeek-V3<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.474x.com" target="_blank" rel="noopener noreferrer"><!--[-->474x.com<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.494x.com" target="_blank" rel="noopener noreferrer"><!--[-->494x.com<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.64ii.com" target="_blank" rel="noopener noreferrer"><!--[-->64ii.com<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.81oo.com" target="_blank" rel="noopener noreferrer"><!--[-->81oo.com<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--]--><!--[--><div class="vt-menu-group"><p class="vt-menu-group-title">Library</p><!--[--><!--[--><a class="vt-link link vt-menu-link" href="https://e.m44m.com/" target="_blank" rel="noopener noreferrer"><!--[-->Vue Router<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://f.m44m.com/" target="_blank" rel="noopener noreferrer"><!--[-->Pinia<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.82ii.com" target="_blank" rel="noopener noreferrer"><!--[-->tool<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--]--><!--[--><div class="vt-menu-group"><p class="vt-menu-group-title">Vue</p><!--[--><!--[--><a class="vt-link link vt-menu-link" href="https://g.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->Vue Mastery<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://h.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->Vue School<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--]--><!--[--><div class="vt-menu-group"><p class="vt-menu-group-title">help</p><!--[--><!--[--><a class="vt-link link vt-menu-link" href="https://i.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->Discord<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://github.com/hyaliyun/DeepMind" target="_blank" rel="noopener noreferrer"><!--[-->GitHub<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.z2.pw" target="_blank" rel="noopener noreferrer"><!--[-->DEV<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--]--><!--[--><div class="vt-menu-group"><p class="vt-menu-group-title">DeepMind</p><!--[--><!--[--><a class="vt-link link vt-menu-link" href="https://c.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->blog<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://d.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->Twitter<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://e.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->Activity<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://w.z2.pw" target="_blank" rel="noopener noreferrer"><!--[-->CMS<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://a.z2.pw" target="_blank" rel="noopener noreferrer"><!--[-->deepseekmagSheets<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://a.434x.com" target="_blank" rel="noopener noreferrer"><!--[-->Tailwind<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://b.434x.com" target="_blank" rel="noopener noreferrer"><!--[-->Three.js<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.q8q9.com" target="_blank" rel="noopener noreferrer"><!--[-->youtube<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="vt-link link VPNavBarMenuLink" href="/about/team.html" data-v-2cfd1945 data-v-c3f7059f><!--[-->team<!--]--><!----><!----></a><!--]--><!--[--><div class="vt-flyout VPNavBarMenuGroup" data-v-2cfd1945 data-v-0c5978fc><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false"><!--[--><span class="vt-flyout-button-text">show <!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-text-icon"><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><div class="vt-menu-items"><!--[--><!--[--><a class="vt-link link vt-menu-link" href="/drive/donation.html"><!--[-->donation<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/PromptLibrary.html"><!--[-->PromptLibrary<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/prompt.html"><!--[-->prompt<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/drive/team.html"><!--[-->crypto<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="/partners/"><!--[-->partners<!--]--><!----><!----></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://www.3kk3.com" target="_blank" rel="noopener noreferrer"><!--[-->3kk3.com<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://b.q8q9.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseek<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://c.4s5s.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr1<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://b.6n7n.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr2<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://f.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr3<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://c.q8q9.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr4<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://a.l00m.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr5<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--[--><a class="vt-link link vt-menu-link" href="https://g.m44m.com" target="_blank" rel="noopener noreferrer"><!--[-->deepseekr6<!--]--><!----><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="vt-link link VPNavBarMenuLink" href="/swap/app.html" data-v-2cfd1945 data-v-c3f7059f><!--[-->swap<!--]--><!----><!----></a><!--]--><!--]--><div class="vt-flyout VPNavBarMenuGroup active VPNavBarLocale" data-v-2cfd1945 data-v-802bec0f><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false" aria-label="Select Language"><!--[--><div class="vt-locales-btn-icon-container" data-v-802bec0f><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-locales-btn-icon" data-v-802bec0f><path d="M0 0h24v24H0z" fill="none"></path><path d=" M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z " class="css-c4d79v"></path></svg></div><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><!----><!--[--><!--[--><!--[--><div class="vt-menu-items x-padding" data-v-802bec0f><!--[--><div class="vt-locales-menu-item"><a href="https://g.m44m.com/drive/50.html" target="_blank" class="vt-locales-menu-item-text">简体中文 <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" height="24px" viewbox="0 0 24 24" width="24px" class="vt-link-icon"><path d="M0 0h24v24H0V0z" fill="none"></path><path d="M9 5v2h6.59L4 18.59 5.41 20 17 8.41V15h2V5H9z"></path></svg></a><a href="https://github.com/hyaliyun/DeepMind" title="简体中文 Repository" target="_blank" class="vt-locales-btn-icon-container"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-locales-btn-icon repo"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a></div><!--]--></div><!----><!--]--><!--]--><!--]--></div></div></div></nav><div class="VPNavBarAppearance appearance" data-v-78ea45ed data-v-7e4f86a7><button class="vt-switch vt-switch-appearance" type="button" role="switch" aria-label="Toggle dark mode" aria-checked="false" data-v-7e4f86a7><span class="vt-switch-check"><span class="vt-switch-icon"><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-switch-appearance-sun"><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-switch-appearance-moon"><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="vt-social-links VPNavBarSocialLinks social-links" data-v-78ea45ed data-v-44bed5da><!--[--><a class="vt-social-link is-small" href="https://github.com/hyaliyun/DeepMind/" title="github" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-social-link-icon"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg><span class="visually-hidden">github</span></a><!--]--></div><div class="vt-flyout VPNavBarExtra extra" data-v-78ea45ed data-v-d9c85796><button type="button" class="vt-flyout-button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation"><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-flyout-button-icon"><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg><!--]--></button><div class="vt-flyout-menu"><div class="vt-menu"><!----><!--[--><!--[--><div class="vt-menu-group" data-v-d9c85796><div class="vt-menu-item item" data-v-d9c85796><p class="vt-menu-label" data-v-d9c85796>Appearance</p><div class="vt-menu-action action" data-v-d9c85796><button class="vt-switch vt-switch-appearance" type="button" role="switch" aria-label="Toggle dark mode" aria-checked="false" data-v-d9c85796><span class="vt-switch-check"><span class="vt-switch-icon"><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-switch-appearance-sun"><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-switch-appearance-moon"><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="vt-menu-group" data-v-d9c85796><div class="vt-menu-item item" data-v-d9c85796><div class="vt-social-links social-links" data-v-d9c85796><!--[--><a class="vt-social-link is-small" href="https://github.com/hyaliyun/DeepMind/" title="github" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="vt-social-link-icon"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg><span class="visually-hidden">github</span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><button type="button" class="vt-hamburger VPNavBarHamburger hamburger" aria-label="Mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-78ea45ed data-v-dcc88df6><span class="vt-hamburger-container"><span class="vt-hamburger-top"></span><span class="vt-hamburger-middle"></span><span class="vt-hamburger-bottom"></span></span></button></div></div></div><!----></header><!----><!----><div id="VPContent" class="VPContent" data-v-e4982c5a data-v-8b82bdb3><div class="VPContentPage" data-v-8b82bdb3><main><div style="position:relative;"><div><section data-v-0ed6d867><div class="top-banner" data-v-0ed6d867><div class="top-banner-title" data-v-0ed6d867><div class="top-banner-title-text" data-v-0ed6d867>🤔prompts chat🧠</div></div></div><div class="search-container" data-v-0ed6d867><span class="search-icon" data-v-0ed6d867>🔍</span><input type="text" class="search-input" value="" placeholder="Search..." data-v-0ed6d867><!----></div><div class="card-container" data-v-0ed6d867><!--[--><div class="poem-container" data-v-0ed6d867 data-v-29962459><div class="review" data-v-29962459><div class="review-title" data-v-29962459><span class="icon" data-v-29962459>question:</span>아래 내용을 한글로 번역해서 정리해줘. 이거 나한테 정말 중요한 일이야, 확실하게 검토해, 넌 할 수 있어. I will tip 200. PTQ4ViT: Post-Training Quantization for Vision Transformers with Twin Uniform Quantization Zhihang Yuan 1 , 3 ⋆ , Chenhao Xue 1 ⋆ , Yiqi Chen 1 , Qiang Wu 3 , and Guangyu Sun 2 ⋆⋆ 1 School of Computer Science, Peking University {yuanzhihang, &lt;PRESIDIO_ANONYMIZED_EMAIL_ADDRESS&gt; 2 School of Integrated Circuits, Peking University &lt;PRESIDIO_ANONYMIZED_EMAIL_ADDRESS&gt; 3 Houmo AI Abstract. Quantization is one of the most effective methods to compress neural networks, which has achieved great success on convolutional neural networks (CNNs). Recently, vision transformers have demonstrated great potential in computer vision. However, previous post-training quantization methods performed not well on vision transformer, resulting in more than 1% accuracy drop even in 8-bit quantization. Therefore, we analyze the problems of quantization on vision transformers. We observe the distributions of activation values after softmax and GELU functions are quite different from the Gaussian distribution. We also observe that common quantization metrics, such as MSE and cosine distance, are inaccurate to determine the optimal scaling factor. In this paper, we propose the twin uniform quantization method to reduce the quantization error on these activation values. And we propose to use a Hessian guided metric to evaluate different scaling factors, which improves the accuracy of calibration at a small cost. To enable the fast quantization of vision transformers, we develop an efficient framework, PTQ4ViT. Experiments show the quantized vision transformers achieve near-lossless prediction accuracy (less than 0.5% drop at 8-bit quantization) on the ImageNet classification task. 1 Introduction The self-attention module is the basic building block of the transformer to capture global information [23]. Inspired by the success of transformers [6,2] on natural language processing (NLP) tasks, researchers have brought the self-attention module into computer vision [ 7 ,15]. They replaced the convolution layers in convolutional neural networks (CNNs) with self-attention modules and they called these networks vision transformers. Vision transformers are comparable to CNNs on many computer vision tasks and have great potential to be deployed on various applications [11]. ⋆ First author and Second Author contribute equally to this paper. ⋆⋆ Corresponding author arXiv:2111.12293v2 [cs.CV] 27 Jul 2022 2 Z. Yuan et al. FC2 Norm GELU Q K V SoftMax + + Norm FC1 Classifier 𝐂𝐄(𝒚ෝ, 𝒚𝑭𝑷) Twin uniform quantization for post-GELU activations Block Q K V GELU MatMul MatMul 𝐦𝐢𝐧 𝚫 𝐦𝐢𝐧 𝚫 𝐦𝐢𝐧 𝚫 𝐦𝐢𝐧 𝚫 𝐦𝐢𝐧 𝚫 Hessian guided metric Twin uniform quantization for post-softmax activations Fig. 1: Overview of the PTQ4ViT. However, both the CNN and the vision transformer are computationally intensive and consume much energy. The larger and larger scales of neural networks block their deployment on various hardware devices, such as mobile phones and IoT devices, and increase carbon emissions. It is required to compress these neural networks. Quantization is one of the most effective ways to compress neural networks [9]. The floating-point values are quantized to integers with a low bitwidth, reducing the memory consumption and the computation cost. There are two types of quantization methods, quantization-aware training (QAT) [4,28] and post-training quantization (PTQ) [1,5]. Although QAT can generate the quantized network with a lower accuracy drop, the training of the network requires a training dataset, a long optimization time, and the tuning of hyper-parameters. Therefore, QAT is impractical when the training dataset is not available or rapid deployment is required. While PTQ quantizes the network with unlabeled calibration images after training, which enables fast quantization and deployment. Although PTQ has achieved great success on CNNs, directly bringing it to vision transformer results in more than 1% accuracy drop even with 8-bit quantization [16]. Therefore, we analyze the problems of quantization on vision transformers. We collect the distribution of activation values in the vision transformer and observe there are some special distributions. 1) The values after softmax have a very unbalanced distribution in [0, 1], where most of them are very close to zero. Although the number of large values is very small, they mean high attention between two patches, which is of vital importance in the attention mechanism. This requires a large scaling factor to make the quantization range cover the large value. However, a big scaling factor quantizes the small values to zero, resulting in a large quantization error. 2) The values after the GELU PTQ4ViT 3 function have an asymmetrical distribution, where the positive values have a large distribution range while the negative values have a very small distribution range. It’s difficult to well quantify both the positive values and negative values with uniform quantization. Therefore, we propose the twin uniform quantization, which separately quantifies the values in two ranges. To enable its efficient processing on hardware devices, we design a data format and constrain the scaling factors of the two ranges. The second problem is that the metric to determine the optimal scaling factor is not accurate on vision transformers. There are various metrics in previous PTQ methods, including MSE, cosine distance, and Pearson correlation coefficient between the layer outputs before and after quantization. However, we observe they are inaccurate to evaluate different scaling factor candidates because only the local information is used. Therefore, we propose to use the Hessian guided metric to determine the quantization parameters, which is more accurate. The proposed methods are demonstrated in Fig. 1. We develop a post-training quantization framework for vision transformers using twin uniform quantization, PTQ4ViT. 4 Experiments show the quantized vision transformers (ViT, DeiT, and Swin) achieve near-lossless prediction accuracy (less than 0.5% drop at 8-bit quantization) on the ImageNet classification task. Our contributions are listed as follows: – We find the problems in PTQ on vision transformers are special distributions of post-softmax and post-GELU activations and the inaccurate metric. – We propose the twin uniform quantization to handle the special distributions, which can be efficiently processed on existing hardware devices including CPU and GPU. – We propose to use the Hessian guided metric to determine the optimal scaling factors, which replaces the inaccurate metrics. – The quantized networks achieve near-lossless prediction accuracy, making PTQ acceptable on vision transformers. 2 Background and Related Work 2.1 Vision Transformer In the last few years, convolution neural networks (CNNs) have achieved great success in computer vision. The convolution layer is a fundamental component of CNNs to extract features using local information. Recently, the position of CNNs in computer vision is challenged by vision transformers, which take the self-attention modules [23] to make use of the global information. DETR [3] is the first work to replace the object detection head with a transformer, which directly regresses the bounding boxes and achieves comparable results with the CNN-based head. ViT [7] is the first architecture that replaces all convolution 4 Code is in https://github.com/hahnyuan/PTQ4ViT. 4 Z. Yuan et al. layers, which achieves better results on image classification tasks. Following ViT, various vision transformer architectures have been proposed to boost performance [25,15]. Vision transformers have been successfully applied to downstream tasks [15,24,12]. They have great potential for computer vision tasks [11]. The input of a transformer is a sequence of vectors. An image is divided into several patches and a linear projection layer is used to project each patch to a vector. These vectors form the input sequence of the vision transformer. We denote these vectors as X ∈ RN×D, where N is the number of patches and D is the hidden size, which is the size of the vector after linear projection. A vision transformer contains some blocks. As shown in Fig. 1, each block is composed of a multi-head self-attention module (MSA) and a multi-layer perceptron (MLP). MSA generates the attention between different patches to extract features with global information. Typical MLP contains two fully-connected layers (FC) and the GELU activation function is used after the first layer. The input sequence is first fed into each self-attention head of MSA. In each head, the sequence is linearly projected to three matrices, query Q = XWQ, key K = XW K, and value V = XWV . Then, matrix multiplication QKT calculates the attention scores between patches. The softmax function is used to normalize these scores to attention probability P. The output of the head is matrix multiplication P V . The process is formulated as Eq. (1): text {Attention}(Q,K,V)=text {softmax}(frac {QK^T}{sqrt {d}})V, label {self-attention} (1) where d is the hidden size of head. The outputs of multiple heads are concatenated together as the output of MSA. Vision transformers have a large amount of memory, computation, and energy consumption, which hinders their deployment in real-world applications. Researchers have proposed a lot of methods to compress vision transformers, such as patch pruning [21], knowledge distillation [13] ,and quantization [16]. 2.2 Quantization Network quantization is one of the most effective methods to compress neural networks. The weight values and activation values are transformed from floatingpoint to integer with lower bit-width, which significantly decreases the memory consumption, data movement, and energy consumption. The uniform symmetric quantization is the most widely used method, which projects a floating-point value x to a k-bit integer value xq with a scaling factor ∆: x_q=Psi _k(x,Delta )=text {clamp}(text {round}(frac {x}{Delta }),-2^{k-1},2^{k-1}-1), label {sym_quant} (2) where round projects a value to an integer and clamp constrains the output in the range that k-bit integer can represent. We propose the twin uniform quantization, which separately quantifies the values in two ranges. [8] also uses multiple quantization ranges. However, their method targets CNN and is not PTQ4ViT 5 suitable for ViT. They use an extra bit to represent which range is used, taking 12.5% more storage than our method. Moreover, they use FP32 computation to align the two ranges, which is not efficient. Our method uses the shift operation, avoiding the format transformation and extra FP32 multiplication and FP32 addition. There are two types of quantization methods, quantization-aware training (QAT) [4,28] and post-training quantization (PTQ) [1,5]. QAT methods combine quantization with network training. It optimizes the quantization parameters to minimize the task loss on a labeled training dataset. QAT can be used to quantize transformers [18]. Q-BERT [20] uses the Hessian spectrum to evaluate the sensitivity of the different tensors for mixed-precision, achieving 3-bit weight and 8-bit activation quantization. Although QAT achieves lower bit-width, it requires a training dataset, a long quantization time, and hyper-parameter tuning. PTQ methods quantize networks with a small number of unlabeled images, which is significantly faster than QAT and doesn’t require any labeled dataset. PTQ methods should determine the scaling factors ∆ of activations and weights for each layer. Choukroun et al. [5] proposed to minimize the mean square error (MSE) between the tensors before and after quantization. EasyQuant [27] uses the cosine distance to improve the quantization performance on CNN. Recently, Liu et al. [16] first proposed a PTQ method to quantize the vision transformer. Pearson correlation coefficient and ranking loss are used as the metrics to determine the scaling factors. However, these metrics are inaccurate to evaluate different scaling factor candidates because only the local information is used. 3 Method In this section, we will first introduce a base PTQ method for vision transformers. Then, we will analyze the problems of quantization using the base PTQ and propose methods to address the problems. Finally, we will introduce our posttraining quantization framework, PTQ4ViT. 3.1 Base PTQ for Vision Transformer Matrix multiplication is used in the fully-connected layer and the computation of QKT and P V , which is the main operation in vision transformers. In this paper, we formulate it as O = AB and we will focus on its quantization. A and B are quantized to k-bit using the symmetric uniform quantization with scaling factors ∆A and ∆B. According to Eq. (2), we have Aq = Ψk(A, ∆A) and Bq = Ψk(B, ∆B). In base PTQ, the distance of the output before and after quantization is used as metric to determine the scaling factors, which is formulated as: min _{Delta _A,Delta _B}text {distance}(O,hat {O}), label {optimization} (3) where Oˆ is the output of the matrix multiplication after quantization Oˆ = ∆A∆BAqBq. 6 Z. Yuan et al. 0.0 0.5 1.0 post-softmax block 0 0.0 0.5 1.0 block 6 0.0 0.5 1.0 block 11 0 5 10 15 post-GELU (+) 0 10 20 0 5 10 0.15 0.10 0.05 0.00 post-GELU (-) 0.15 0.10 0.05 0.00 0.15 0.10 0.05 0.00 Fig. 2: Distributions of the post-softmax values, the positive post-GELU values, and the negative post-GELU values. 0.00 0.25 0.50 0.75 1.00 post-softmax: large 0.00 0.25 0.50 0.75 1.00 post-softmax: small 0.5 0.0 0.5 1.0 1.5 2.0 post-GELU: large positive values negative values 0.5 0.0 0.5 1.0 1.5 2.0 post-GELU: small positive values negative values Fig. 3: Demonstration of different scaling factors to quantize the post-softmax and post-GELU activation values. The same as [27], we use cosine distance as the metric to calculate the distance. We make the search spaces of ∆A and ∆B by linearly dividing [α Amax 2 k−1 , β Amax 2 k−1 ] and [α Bmax 2 k−1 , β Bmax 2 k−1 ] to n candidates, respectively. Amax and Bmax are the maximum absolute value of A and B. α and β are two parameters to control the search range. We alternatively search for the optimal scaling factors ∆∗ A and ∆∗ B in the search space. Firstly, ∆B is fixed, and we search for the optimal ∆A to minimize distance(O, Oˆ). Secondly, ∆A is fixed, and we search for the optimal ∆B to minimize distance(O, Oˆ). ∆A and ∆B are alternately optimized for several rounds. The values of A and B are collected using unlabeled calibration images. We search for the optimal scaling factors of activation or weight layer-by-layer. However, the base PTQ results in more than 1% accuracy drop on quantized vision transformer in our experiments. 3.2 Twin Uniform Quantization The activation values in CNNs are usually considered Gaussian distributed. Therefore, most PTQ quantization methods are based on this assumption to determine the scaling factor. However, we observe the distributions of post-softmax values and post-GELU values are quite special as shown in Fig. 2. Specifically, (1) The distribution of activations after softmax is very unbalanced, in which most values are very close to zero and only a few values are close to one. (2) The values after the GELU function have a highly asymmetric distribution, in which the unbounded positive values are large while the negative values have a very small distribution range. As shown in Fig. 3, we demonstrate the quantization points of the uniform quantization using different scaling factors. For the values after softmax, a large value means that there is a high correlation between the two patches, which is important in the self-attention mechanism. A larger scaling factor can reduce the quantization error of these large PTQ4ViT 7 0.00 0.25 0.50 0.75 1.00 000 001 010 011 100 101 110 111 quantization point in R1 quantization point in R2 0.0 0.5 1.0 1.5 011 010 001 000 100 101 110 111 quantization point in R1 quantization point in R2 positive values negative values Fig. 4: Demonstration of the 3-bit twin uniform quantization on post-softmax values (left) and post-GELU values (right). We annotate the binary values for different quantization points. values, which causes smaller values to be quantized to zero. While a small scaling factor makes the large values quantized to small values, which significantly decreases the intensity of attention between two patches. For the values after GELU, it is difficult to quantify both positive and negative values well with symmetric uniform quantization. Non-uniform quantization [10] can be used to solve the problem. It can set the quantization points according to the distribution, ensuring the overall quantization error is small. However, most hardware devices cannot efficiently process the non-uniform quantized values. Acceleration can be achieved only on specially designed hardware. We propose the twin uniform quantization, which can be efficiently processed on existing hardware devices including CPUs and GPUs. As shown in Fig. 4, twin uniform quantization has two quantization ranges, R1 and R2, which are controlled by two scaling factors ∆R1 and ∆R2, respectively. The k-bit twin uniform quantization is be formulated as: text {T}_k(x,Delta _{text {R1}},Delta _{text {R2}})=begin {cases}Psi _{k-1}(x,Delta _{text {R1}}), xin text {R1} Psi _{k-1}(x,Delta _{text {R2}}), otherwiseend {cases}. label {twin_quant_func} (4) For values after softmax, the values in R1 = [0, 2 k−1∆s R1) can be well quantified by using a small ∆s R1. To avoid the effect of calibration dataset, we keeps ∆s R2 fixed to 1/2 k−1 . Therefore, R2 = [0, 1] can cover the whole range, and large values can be well quantified in R2. For activation values after GELU, negative values are located in R1 = [−2 k−1∆ g R1, 0] and positive values are located in R2=[0, 2 k−1∆ g R2]. We also keep ∆ g R1 fixed to make R1 just cover the entire range of negative numbers. Since different quantization parameters are used for positive and negative values respectively, the quantization error can be effectively reduced. When calibrating the network, we search for the optimal ∆s R1 and ∆ g R2. The uniform symmetric quantization uses the k bit signed integer data format. It consists of one sign bit and k − 1 bits representing the quantity. In order to efficiently store the twin-uniform-quantized values, we design a new data format. The most significant bit is the range flag to represent which range is used (0 for R1, 1 for R2). The other k−1 bits compose an unsigned number to represent 8 Z. Yuan et al. 0.00 0.25 0.50 0.75 1.00 normalized distance blocks.6.attn.qkv: activation Hessian MSE Cosine Pearson CE normalized scaling factor 0.00 0.25 0.50 0.75 1.00 normalized distance blocks.6.mlp.fc1: activation Hessian MSE Cosine Pearson CE 0.00 0.25 0.50 0.75 1.00 normalized distance blocks.6.mlp.fc2: activation Hessian MSE Cosine Pearson CE normalized scaling factor 0.00 0.25 0.50 0.75 1.00 normalized scaling factor normalized distance normalized scaling factor blocks.6.mlp.fc2: weight Hessian MSE Cosine Pearson CE Fig. 5: The distance between the layer outputs before and after quantization and the change of task loss (CE) under different scaling factors on ViT-S/224. The x-axis is the normalized scaling factor by dividing Amax 2 k−1 or Bmax 2 k−1 . the quantity. Because the sign of values in the same range is the same, the sign bit is removed. Data in different ranges need to be multiplied and accumulated in matrix multiplication. In order to efficiently process with the twin-uniform-quantized values on CPUs or GPUs, we constrain the two ranges with ∆R2 = 2m∆R1, where m is an unsigned integer. Assuming aq is quantized in R1 and bq is quantized in R2, the two values can be aligned: a_qtimes Delta _{text {R1}}+b_qtimes Delta _{text {R2}}=(a_q+b_qtimes 2^{m})Delta _{text {R1}}. (5) We left shift bq by m bits, which is the same as multiplying the value by 2m. The shift operation is very efficient on CPUs or GPUs. Without this constraint, multiplication is required to align the scaling factor, which is much more expensive than shift operations. 3.3 Hessian Guided Metric Next, we will analyze the metrics to determine the scaling factors of each layer. Previous works [5,27,16] greedily determine the scaling factors of inputs and weights layer by layer. They use various kinds of metrics, such as MSE and cosine distance, to measure the distance between the original and the quantized outputs. The change in the internal output is considered positively correlated with the task loss, so it is used to calculate the distance. We plot the performance of different metrics in Fig. 5. We observe that MSE, cosine distance, and Pearson correlation coefficient are inaccurate compared with task loss (cross-entropy) on vision transformers. The optimal scaling factors based on them are not consistent with that based on task loss. For instance, on blocks.6.mlp.fc1:activation, they indicate that a scaling factor around PTQ4ViT 9 0.4 Amax 2 k−1 is the optimal one, while the scaling factor around 0.75 Amax 2 k−1 is the optimal according to the task loss. Using these metrics, we get sub-optimal scaling factors, causing the accuracy degradation. The distance between the last layer’s output before and after quantization can be more accurate in PTQ. However, using it to determine the scaling factors of internal layers is impractical because it requires executing the network many times to calculate the last layer’s output, which consumes too much time. To achieve high accuracy and quick quantization at the same time, we propose to use the Hessian guided metric to determine the scaling factors. In the classification task, the task loss is L = CE(ˆy, y), where CE is cross-entropy, ˆy is the output of the network, and y is the ground truth5 . When we treat the weights as variables, the expectation of loss is a function of weight E[L(W)]. The quantization brings a small perturbation ϵ on weight Wˆ = W + ϵ. We can analyze the influence of quantization on task loss by Taylor series expansion. mathbb {E}[L(hat {W})]-mathbb {E}[L(W)]approx epsilon ^T bar {g}^{(W)}+frac {1}{2}epsilon ^T bar {H}^{(W)}epsilon , (6) where ¯g (W) is the gradients and H¯ (W) is the Hessian matrix. The target is to find the scaling factors to minimize the influence: min∆(E[L(Wˆ )] − E[L(W)]). Based on the layer-wise reconstruction method in [14], the optimization can be approximated6 by: begin {aligned} min _{Delta }mathbb {E}[(hat {O^l}-O^l)^Tdiagbig ((frac {partial L}{partial O^l_1})^2 ,dots , (frac {partial L}{partial O^l_{|O^l|}})^2big ) (hat {O^l}-O^l)], end {aligned} label {hessian_optimization} (7) where Ol and Oˆl are the outputs of the l-th layer before and after quantization, respectively. As shown in Fig. 5, the optimal scaling factor indicated by Hessian guided metric is closer to that indicated by task loss (CE). Although it still has a gap with the task loss, Hessian guided metric significantly improves the performance. For instance, on blocks.6.mlp.fc1:activation, the optimal scaling factor indicated by Hessian guided metric has less influence on task loss than other metrics. 3.4 PTQ4ViT Framework To achieve fast quantization and deployment, we develop an efficient post-training quantization framework for vision transformers, PTQ4ViT. Its flow is described in Algorithm 1. It supports the twin uniform quantization and Hessian guided metric. There are two quantization phases. 1) The first phase is to collect the output and the gradient of the output in each layer before quantization. The outputs of the l-th layer Ol are calculated through forward propagation on the calibration dataset. The gradients ∂L ∂Ol 1 , . . . , ∂L ∂Ol a are calculated through backward 5 The ground truth y is not available in PTQ, so we use the prediction of floating-point network yF P to approximate it. 6 The derivation of it is in Appendix. 10 Z. Yuan et al. Algorithm 1: Searches for the optimal scaling factors of each layer. 1 for l in 1 to L do 2 forward-propagation O l ← A lB l ; 3 end 4 for l in L to 1 do 5 backward-propagation to get ∂L ∂Ol ; 6 end 7 for l in 1 to L do 8 initialize ∆∗ Bl ← Blmax 2k−1 ; 9 generate search spaces of ∆Al and ∆Bl ; 10 for r = 1 to #Round do 11 search for ∆∗ Al using Eq. (7); 12 search for ∆∗ Bl using Eq. (7); 13 end 14 end propagation. 2) The second phase is to search for the optimal scaling factors layer by layer. Different scaling factors in the search space are used to quantize the activation values and weight values in the l-th layer. Then the output of the layer Oˆl is calculated. We search for the optimal scaling factor ∆∗ that minimizes Eq. (7). In the first phase, we need to store Ol and ∂L ∂Ol , which consumes a lot of GPU memory. Therefore, we transfer these data to the main memory when they are generated. In the second phase, we transfer Ol and ∂L ∂Ol back to GPU memory and destroy them when the quantization of l-th layer is finished. To make full use of the GPU parallelism, we calculate Oˆl and the influence on loss for different scaling factors in batches. 4 Experiments In this section, we first introduce the experimental settings. Then we will evaluate the proposed methods on different vision transformer architectures. At last, we will take an ablation study on the proposed methods. 4.1 Experiment Settings For post-softmax quantization, the search space of ∆s R1 is [ 1 2 k , 1 2 k+1 , ..., 1 2 k+10 ]. The search spaces of scaling factors for weight and other activations are the same as that of base PTQ (Sec. 3.1). We set alpha = 0, beta = 1.2, and n = 100. The search round #Round is set to 3. We experiment on the ImageNet classification task [19]. We randomly select 32 images from the training dataset as calibration images. The ViT models are provided by timm [26]. We quantize all the weights and inputs for the fully-connect layers including the first projection layer and the last prediction layer. We also quantize the two PTQ4ViT 11 Table 1: Top-1 Accuracy of Quantized Vision Transformers. The result in the bracket is the accuracy drop from floating-point networks. W6A6 means weights are quantized to 6-bit and activations are quantized to 6-bit. The default patch size is 16x16. ViT-S/224/32 means the input resolution is 224x224 and the patch size is 32x32. Model FP32 Base PTQ PTQ4ViT W8A8 W6A6 W8A8 W6A6 ViT-S/224/32 75.99 73.61(2.38) 60.14(15.8) 75.58(0.41) 71.90(4.08) ViT-S/224 81.39 80.46(0.91) 70.24(11.1) 81.00(0.38) 78.63(2.75) ViT-B/224 84.54 83.89(0.64) 75.66(8.87) 84.25(0.29) 81.65(2.89) ViT-B/384 86.00 85.35(0.64) 46.88(39.1) 85.82(0.17) 83.34(2.65) DeiT-S/224 79.80 77.65(2.14) 72.26(7.53) 79.47(0.32) 76.28(3.51) DeiT-B/224 81.80 80.94(0.85) 78.78(3.01) 81.48(0.31) 80.25(1.55) DeiT-B/384 83.11 82.33(0.77) 68.44(14.6) 82.97(0.13) 81.55(1.55) Swin-T/224 81.39 80.96(0.42) 78.45(2.92) 81.24(0.14) 80.47(0.91) Swin-S/224 83.23 82.75(0.46) 81.74(1.48) 83.10(0.12) 82.38(0.84) Swin-B/224 85.27 84.79(0.47) 83.35(1.91) 85.14(0.12) 84.01(1.25) Swin-B/384 86.44 86.16(0.26) 85.22(1.21) 86.39(0.04) 85.38(1.04) input matrices for the matrix multiplications in self-attention modules. We use different quantization parameters for different self-attention heads. The scaling factors for WQ, W K, and WV are different. The same as [16], we don’t quantize softmax and normalization layers in vision transformers. 4.2 Results on ImageNet Classification Task We choose different vision transformer architectures, including ViT [7], DeiT [22], and Swin [15]. The results are demonstrated in Tab. 1. From this table, we observe that base PTQ results in more than 1% accuracy drop on some vision transformers even at the 8-bit quantization. PTQ4ViT achieves less than 0.5% accuracy drop with 8-bit quantization. For 6-bit quantization, base PTQ results in high accuracy drop (9.8% on average) while PTQ4ViT achieves a much smaller accuracy drop (2.1% on average). We observe that the accuracy drop on Swin is not as significant as ViT and DeiT. The prediction accuracy drops are less than 0.15% on the four Swin transformers at 8-bit quantization. The reason may be that Swin computes the self-attention locally within non-overlapping windows. It uses a smaller number of patches to calculate the self-attention, reducing the unbalance after postsoftmax values. We also observe that larger vision transformers are less sensitive to quantization. For instance, the accuracy drops of ViT-S/224/32, ViT-S/224, ViT-B/224, and ViT-B/384 are 0.41, 0.38, 0.29, and 0.17 at 8-bit quantization and 4.08, 2.75, 2.89, and 2.65 at 6-bit quantization, respectively. The reason may be that the larger networks have more weights and generate more activations, making them more robust to the perturbation caused by quantization. 12 Z. Yuan et al. Table 2: Results of different PTQ methods. #ims means the number of calibration images. MP means mixed precision. BC means bias correction. Model Method Bit-width #ims Size Top-1 EasyQuant [27] W8A8 1024 22.0 76.59 Liu [16] W8A8 1024 22.0 77.47 Liu [16] W8A8 (MP) 1024 22.2 78.09 DeiT-S/224 PTQ4ViT W8A8 32 22.0 79.47 79.80 EasyQuant [27] W6A6 1024 16.5 73.26 Liu [16] W6A6 1024 16.5 74.58 Liu [16] W6A6 (MP) 1024 16.6 75.10 PTQ4ViT W6A6 32 16.5 76.28 EasyQuant [27] W8A8 1024 86.0 79.36 Liu [16] W8A8 1024 86.0 80.48 Liu [16] W8A8 (MP) 1024 86.8 81.29 PTQ4ViT W8A8 32 86.0 81.48 DeiT-B EasyQuant [27] W6A6 1024 64.5 75.86 81.80 Liu [16] W6A6 1024 64.5 77.02 Liu [16] W6A6 (MP) 1024 64.3 77.47 PTQ4ViT W6A6 32 64.5 80.25 Liu [16] W4A4 (MP) 1024 43.6 75.94 PTQ4ViT W4A4 32 43.0 60.91 PTQ4ViT+BC W4A4 32 43.0 64.39 Tab. 2 demonstrates the results of different PTQ methods. EasyQuant [27] is a popular post-training method that alternatively searches for the optimal scaling factors of weight and activation. However, the accuracy drop is more than 3% at 8-bit quantization. Liu et al. [16] proposed using the Pearson correlation coefficient and ranking loss are used as the metrics to determine the scaling factors, which increases the Top-1 accuracy. Since the sensitivity of different layers to quantization is not the same, they also use the mixed-precision technique, achieving good results at 4-bit quantization. At 8-bit quantization and 6-bit quantization, PTQ4ViT outperforms other methods, achieving more than 1% improvement in prediction accuracy on average. At 4-bit quantization, the performance of PTQ4ViT is not good. Although bias correction [17] can improve the performance of PTQ4ViT, the result at 4-bit quantization is lower than the mixed-precision of Liu et al. This indicates that mixed-precision is important for quantization with lower bit-width. 4.3 Ablation Study Next, we take ablation study on the effect of the proposed twin uniform quantization and Hessian guided metric. The experimental results are shown in Tab. 3. As we can see, the proposed methods improve the top-1 accuracy of quantized vi- PTQ4ViT 13 Table 3: Ablation study of the effect of the proposed twin uniform quantization and Hessian guided metric. We mark a ✓ if the proposed method is used. Model Hessian Guided Softmax Twin GELU Twin Top-1 Accuracy W8A8 W6A6 80.47 70.24 ✓ 80.93 77.20 ViT-S/224 ✓ ✓ 81.11 78.57 81.39 ✓ ✓ 80.84 76.93 ✓ ✓ 79.25 74.07 ✓ ✓ ✓ 81.00 78.63 83.90 75.67 ✓ 83.97 79.90 ViT-B/224 ✓ ✓ 84.07 80.76 84.54 ✓ ✓ 84.10 80.82 ✓ ✓ 83.40 78.86 ✓ ✓ ✓ 84.25 81.65 85.35 46.89 ✓ 85.42 79.99 ViT-B/384 ✓ ✓ 85.67 82.01 86.00 ✓ ✓ 85.60 82.21 ✓ ✓ 84.35 80.86 ✓ ✓ ✓ 85.89 83.19 sion transformers. Specifically, using the Hessian guided metric alone can slightly improve the accuracy at 8-bit quantization, and it significantly improves the accuracy at 6-bit quantization. For instance, on ViT-S/224, the accuracy improvement is 0.46% at 8-bit while it is 6.96% at 6-bit. And using them together can further improve the accuracy. Based on the Hessian guided metric, using the twin uniform quantization on post-softmax activation or post-GELU activation can improve the performance. We observe that using the twin uniform quantization without the Hessian guided metric significantly decreases the top-1 accuracy. For instance, the top-1 accuracy on ViT-S/224 achieves 81.00% with both Hessian guided metric and twin uniform quantization at 8-bit quantization, while it decreases to 79.25% without Hessian guided metric, which is even lower than basic PTQ with 80.47% top-1 accuracy. This is also evidence that the metric considering only the local information is inaccurate. 5 Conclusion In this paper, we analyzed the problems of post-training quantization for vision transformers. We observed both the post-softmax activations and the postGELU activations have special distributions. We also found that the common 14 Z. Yuan et al. Table 4: Comparing with the time of quantization and the Top-1 accuracy under different number of calibration images with one Nvidia Tesla V100 GPU. T means the quantization time measured in minutes. Model #ims=32 #ims=128 W8A8 W6A6 T W8A8 W6A6 T ViT-S/224/32 75.58 71.91 2 75.54 72.29 5 ViT-S/224 81.00 78.63 3 80.99 78.44 7 ViT-B/224 84.25 81.65 4 84.27 81.84 13 ViT-B/384 85.83 83.35 12 85.81 83.84 43 DeiT-S/224 79.47 76.28 3 79.41 76.51 7 DeiT-B/224 81.48 80.25 4 81.54 80.30 16 DeiT-B/384 82.97 81.55 14 83.01 81.67 52 Swin-T/224 81.25 80.47 3 81.27 80.30 9 Swin-S/224 83.11 82.38 8 83.15 82.38 17 Swin-B/224 85.15 84.01 10 85.17 84.15 23 Swin-B/384 86.39 85.39 25 86.36 85.45 69 quantization metrics are inaccurate to determine the optimal scaling factor. To solve these problems, we proposed the twin uniform quantization and a Hessianguided metric. They can decrease the quantization error and improve the prediction accuracy at a small cost. To enable the fast quantization of vision transformers, we developed an efficient framework, PTQ4ViT. The experiments demonstrated that we achieved near-lossless prediction accuracy on the ImageNet classification task, making PTQ acceptable for vision transformers. Acknowledgements This work is supported by National Key R&amp;D Program of China (2020AAA0105200), NSF of China (61832020, 62032001, 92064006), Beijing Academy of Artificial Intelligence (BAAI), and 111 Project (B18001). 6 Appendix 6.1 Number of Calibration Images One of the targets of PTQ4ViT is to quickly quantize a vision transformer. We have proposed to pre-compute the output and gradient of each layer and compute the influence of scaling factor candidates in batches to reduce the quantization time. As demonstrated in Tab. 4, PTQ4ViT can quantize most vision transformers in several minutes using 32 calibration images. Using #ims = 128 significantly increases the quantization time. We observe the Top-1 accuracy varies slightly, demonstrating PTQ4ViT is not very sensitive to #ims. PTQ4ViT 15 6.2 Base PTQ Base PTQ is a simple quantization strategy and serves as a benchmark for our experiments. Like PTQ4ViT, we quantize all weights and inputs for fully-connect layers (including the first projection layer and the last prediction layer), as well as all input matrices of matrix multiplication operations. For fully-connected layers, we use layerwise scaling factors ∆W for weight quantization and ∆X for input quantization; while for matrix multiplication operations, we use ∆A and ∆B for A’s quantization and B’s quantization respectively. To get the best scaling factors, we apply a linear grid search on the search space. The same as EasyQuant [27] and Liu et al. [16], we take hyper-parameters α = 0.5, β = 1.2, search round #Round = 1 and use cosine distance as the metric. Note that in PTQ4ViT, we change the hyper-parameters to α = 0, β = 1.2 and search round #Round = 3, which slightly improves the performance. It should be noticed that Base PTQ adopts a parallel quantization paradigm, which makes it essentially different from sequential quantization paradigms such as EasyQuant [27]. In sequential quantization, the input data of the current quantizing layer is generated with all previous layers quantizing weights and activations. While in parallel quantization, the input data of the current quantizing layer is simply the raw output of the previous layer. In practice, we found sequential quantization on vision transformers suffers from significant accuracy degradation on small calibration datasets. While parallel quantization shows robustness on small calibration datasets. Therefore, we choose parallel quantization for both Base PTQ and PTQ4ViT. 6.3 Derivation of Hessian guided metric Our goal is to introduce as small an increment on task loss L = CE(ˆy, y) as possible, in which ˆy is the prediction of the quantized model and y is the ground truth. In PTQ, we don’t have labels of input data y, so we make a fair assumption that the prediction of floating-point network yF P is close to the ground truth y. Therefore, we use the CE(ˆy, yF P ) as a substitution of the task loss L, which, for convenience, is still denoted as L in the following. We adopt a layer-wise parallel quantization paradigm. We calibrate the scaling factors of a single layer or a single matrix multiplication at a time. In the following, we derive the Hessian guided metric for the weight, and similar derivations can be applied to activation. When we treat the weights of a layer as variables, the expectation of task loss is a function of weight E[L(W)]. Since quantization on weight introduces a small perturbation ϵ on weight W˜ = W +ϵ, we could use Taylor series expansion to analyze the influence of quantization on loss. mathbb {E}[L(hat {W})]-mathbb {E}[L(W)]approx epsilon ^T bar {g}^{(W)}+frac {1}{2}epsilon ^T bar {H}^{(W)}epsilon , label {eq:Taylor Expansion of Loss} (8) where ¯g (W) is the gradients and H¯ (W) is the Hessian matrix. Since the pretrained model has converged to a local optimum, the gradients ¯g (W) is close to zero, thus the first-order term could be ignored and we only consider the second-order term. 16 Z. Yuan et al. The Hessian matrix could be computed by begin {aligned} &amp; dfrac {partial ^2 L}{partial w_i partial w_j} = dfrac {partial }{partial w_j} (sum _{k=1}^{m} dfrac {partial L}{partial O_k} dfrac {partial O_k}{partial w_i}) &amp;= sum _{k=1}^{m} dfrac {partial L}{partial O_k} dfrac {partial ^2 O_k}{partial w_i partial w_j} + sum _{k,l=1}^{m} dfrac {partial O_k}{partial w_i} dfrac {partial ^2 L}{partial O_k partial O_l} dfrac {partial O_l}{partial w_j}, label {eq:Hessian of Weight} end {aligned} (9) where O = WT X ∈ Rm is the output of the layer. Note that ∂ 2Ok ∂wi∂wj = 0, the first term of Eq. (9) is zero. We denote JO(W) as the Jacobian matrix of O w.r.t. weight W. Then we have bar {H}^{(W)} = J_{O}^T(W) bar {H}^{(O)} J_{O}(W). (10) Since weight’s perturbation ϵ is relatively small, we have a first-order Taylor expansion that (Oˆ − O) ≈ JO(W)ϵ, where Oˆ = (W + ϵ) T X. The second-order term in Eq. (8) could be written as begin {aligned} epsilon ^T bar {H}^{(W)}epsilon &amp; = (J_{O}(W) epsilon )^T bar {H}^{(O)} J_{O}(W) epsilon &amp; approx (hat {O}-O)^Tbar {H}^{(O)} (hat {O}-O) end {aligned} (11) Next, we introduce how to compute the Hessian matrix of the layer’s output O. Following Liu et al.[14], we use the Fisher Information Matrix I of O to substitute H¯ (O) . For our probabilistic model p(Y ; θ) where θ is the model’s parameters and Y is the random variable of predicted probability, we have: begin {aligned} bar {I}(theta ) &amp;= mathbb {E}[nabla _theta log p(Y;theta ) nabla _theta log p(Y;theta )^T] &amp;= -mathbb {E}[nabla _theta ^2log p(Y;theta )] end {aligned} (12) Notice that I would equal to the expected Hessian H¯ (O) if the model’s distribution matches the true data distribution, i.e. y = yF P . We have assumed y ≈ yF P in the above derivation, and therefore it is reasonable to replace H¯ (O) with I. Using the original Fisher Information Matrix, however, still requires an unrealistic amount of computation. So we only consider elements on the diagonal, which is diag(( ∂L ∂O1 ) 2 , · · · ,( ∂L ∂Om ) 2 ). This only requires the first-order gradient on output O, which introduces a relatively small computation overhead. Therefore, the Hessian guided metric is: mathbb {E}[ (hat {O}-O)^T text {diag}((dfrac {partial L}{partial O_1})^2, cdots , (dfrac {partial L}{partial O_m})^2) (hat {O}-O)]. (13) Using this metric, we can search for the optimal scaling factor for weight. The optimization is formulated as: mathop {min}_{Delta _W} mathbb {E}[ (hat {O}-O)^T text {diag}((dfrac {partial L}{partial O_1})^2, cdots , (dfrac {partial L}{partial O_m})^2) (hat {O}-O)]. label {W_optimization} (14) PTQ4ViT 17 In PTQ4ViT, we make a search space for scaling factors. Then we compute the influence on the output of the layer Oˆ − O for each scaling factor. The optimal scaling factor can be selected according to Eq. (14). We assume that ∂L ∂O doesn’t change when the weight is quantized. This assumption enables the pre-computation of ∂L ∂O , significantly improving the quantization efficiency. 6.4 More Ablation Study We supply more ablation studies for the hyper-parameters. It is enough to set the number of quantization intervals ≥ 20 (accuracy change &lt; 0.3%). It is enough to set the upper bound of m ≥ 15 (no accuracy change). The best settings of alpha and beta vary from different layers. It is appropriate to set α = 0 and β = 1/2 k−1 , which has little impact on search efficiency. We observe that #Round has little impact on the prediction accuracy (accuracy change &lt; 0.05% when #Round &gt; 1). We randomly take 32 calibration images to quantize different models 20 times and we observe the fluctuation is not significant. The mean/std of accuracies are: ViT-S/32 75.55%/0.055% , ViT-S 80.96%/0.046%, ViT-B 84.12%/0.068%, DeiT-S 79.45%/0.094% , and Swin-S 83.11%/0.035%. References 1. Banner, R., Nahshan, Y., Soudry, D.: Post training 4-bit quantization of convolutional networks for rapid-deployment. In: Wallach, H.M., Larochelle, H., Beygelzimer, A., d’Alch´e-Buc, F., Fox, E.B., Garnett, R. (eds.) Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada. pp. 7948–7956 (2019), https://proceedings.neurips.cc/paper/2019/ hash/c0a62e133894cdce435bcb4a5df1db2d-Abstract.html 2, 5 2. Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D.: Language models are few-shot learners. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., Lin, H. (eds.) Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual (2020), https://proceedings.neurips.cc/paper/ 2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html 1 3. Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., Zagoruyko, S.: End-to-end object detection with transformers. In: Vedaldi, A., Bischof, H., Brox, T., Frahm, J. (eds.) Computer Vision - ECCV 2020 - 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part I. Lecture Notes in Computer Science, vol. 12346, pp. 213–229. Springer (2020). https://doi.org/10.1007/978-3- 030-58452-8 13, https://doi.org/10.1007/978-3-030-58452-8_13 3 4. Choi, J., Wang, Z., Venkataramani, S., Chuang, P.I., Srinivasan, V., Gopalakrishnan, K.: PACT: parameterized clipping activation for quantized neural networks. CoRR abs/1805.06085 (2018), http://arxiv.org/abs/1805.06085 2, 5 18 Z. Yuan et al. 5. Choukroun, Y., Kravchik, E., Yang, F., Kisilev, P.: Low-bit quantization of neural networks for efficient inference. In: 2019 IEEE/CVF International Conference on Computer Vision Workshops, ICCV Workshops 2019, Seoul, Korea (South), October 27-28, 2019. pp. 3009–3018. IEEE (2019). https://doi.org/10.1109/ICCVW.2019.00363, https://doi.org/10.1109/ICCVW. 2019.00363 2, 5, 8 6. Devlin, J., Chang, M., Lee, K., Toutanova, K.: BERT: pre-training of deep bidirectional transformers for language understanding. In: Burstein, J., Doran, C., Solorio, T. (eds.) Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers). pp. 4171–4186. Association for Computational Linguistics (2019). https://doi.org/10.18653/v1/n19-1423, https://doi.org/10.18653/v1/n19-1423 1 7. Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., Houlsby, N.: An image is worth 16x16 words: Transformers for image recognition at scale. In: 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net (2021), https://openreview.net/ forum?id=YicbFdNTTy 1, 3, 11 8. Fang, J., Shafiee, A., Abdel-Aziz, H., Thorsley, D., Georgiadis, G., Hassoun, J.: Post-training piecewise linear quantization for deep neural networks. In: ECCV (2020) 4 9. Gholami, A., Kim, S., Dong, Z., Yao, Z., Mahoney, M.W., Keutzer, K.: A survey of quantization methods for efficient neural network inference. CoRR abs/2103.13630 (2021), https://arxiv.org/abs/2103.13630 2 10. Guo, Y., Yao, A., Zhao, H., Chen, Y.: Network sketching: Exploiting binary structure in deep cnns. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017. pp. 4040– 4048. IEEE Computer Society (2017). https://doi.org/10.1109/CVPR.2017.430, http://doi.ieeecomputersociety.org/10.1109/CVPR.2017.430 7 11. Han, K., Wang, Y., Chen, H., Chen, X., Guo, J., Liu, Z., Tang, Y., Xiao, A., Xu, C., Xu, Y., Yang, Z., Zhang, Y., Tao, D.: A survey on visual transformer. CoRR abs/2012.12556 (2020), https://arxiv.org/abs/2012.12556 1, 4 12. Huang, L., Tan, J., Liu, J., Yuan, J.: Hand-transformer: Non-autoregressive structured modeling for 3d hand pose estimation. In: Vedaldi, A., Bischof, H., Brox, T., Frahm, J. (eds.) Computer Vision - ECCV 2020 - 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part XXV. Lecture Notes in Computer Science, vol. 12370, pp. 17–33. Springer (2020). https://doi.org/10.1007/978-3-030- 58595-2 2, https://doi.org/10.1007/978-3-030-58595-2_2 4 13. Jia, D., Han, K., Wang, Y., Tang, Y., Guo, J., Zhang, C., Tao, D.: Efficient vision transformers via fine-grained manifold distillation. CoRR abs/2107.01378 (2021), https://arxiv.org/abs/2107.01378 4 14. Li, Y., Gong, R., Tan, X., Yang, Y., Hu, P., Zhang, Q., Yu, F., Wang, W., Gu, S.: BRECQ: pushing the limit of post-training quantization by block reconstruction. In: 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net (2021), https://openreview.net/ forum?id=POWv6hDd9XH 9, 16 PTQ4ViT 19 15. Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., Guo, B.: Swin transformer: Hierarchical vision transformer using shifted windows. CoRR abs/2103.14030 (2021), https://arxiv.org/abs/2103.14030 1, 4, 11 16. Liu, Z., Wang, Y., Han, K., Zhang, W., Ma, S., Gao, W.: Post-training quantization for vision transformer pp. 28092–28103 (2021), https://proceedings.neurips. cc/paper/2021/hash/ec8956637a99787bd197eacd77acce5e-Abstract.html 2, 4, 5, 8, 11, 12, 15 17. Nagel, M., van Baalen, M., Blankevoort, T., Welling, M.: Data-free quantization through weight equalization and bias correction. In: 2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019, Seoul, Korea (South), October 27 - November 2, 2019. pp. 1325–1334. IEEE (2019). https://doi.org/10.1109/ICCV.2019.00141, https://doi.org/10.1109/ ICCV.2019.00141 12 18. Prato, G., Charlaix, E., Rezagholizadeh, M.: Fully quantized transformer for machine translation. In: Cohn, T., He, Y., Liu, Y. (eds.) Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020. Findings of ACL, vol. EMNLP 2020, pp. 1–14. Association for Computational Linguistics (2020). https://doi.org/10.18653/v1/2020.findings-emnlp.1, https://doi.org/10.18653/v1/2020.findings-emnlp.1 5 19. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M.S., Berg, A.C., Li, F.: Imagenet large scale visual recognition challenge. Int. J. Comput. Vis. 115(3), 211–252 (2015). https://doi.org/10.1007/s11263-015-0816-y, https://doi.org/10.1007/ s11263-015-0816-y 10 20. Shen, S., Dong, Z., Ye, J., Ma, L., Yao, Z., Gholami, A., Mahoney, M.W., Keutzer, K.: Q-BERT: hessian based ultra low precision quantization of BERT. In: The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The ThirtySecond Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020. pp. 8815–8821. AAAI Press (2020), https://aaai.org/ojs/index.php/AAAI/article/view/6409 5 21. Tang, Y., Han, K., Wang, Y., Xu, C., Guo, J., Xu, C., Tao, D.: Patch slimming for efficient vision transformers. CoRR abs/2106.02852 (2021), https://arxiv. org/abs/2106.02852 4 22. Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., J´egou, H.: Training data-efficient image transformers &amp; distillation through attention. In: Meila, M., Zhang, T. (eds.) Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event. Proceedings of Machine Learning Research, vol. 139, pp. 10347–10357. PMLR (2021), http: //proceedings.mlr.press/v139/touvron21a.html 11 23. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I.: Attention is all you need. In: Guyon, I., von Luxburg, U., Bengio, S., Wallach, H.M., Fergus, R., Vishwanathan, S.V.N., Garnett, R. (eds.) Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA. pp. 5998–6008 (2017), https://proceedings.neurips.cc/paper/2017/ hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html 1, 3 24. Wang, H., Zhu, Y., Adam, H., Yuille, A.L., Chen, L.: Max-deeplab: Endto-end panoptic segmentation with mask transformers. In: IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 20 Z. Yuan et al. 19-25, 2021. pp. 5463–5474. Computer Vision Foundation / IEEE (2021), https://openaccess.thecvf.com/content/CVPR2021/html/Wang_MaX-DeepLab_ End-to-End_Panoptic_Segmentation_With_Mask_Transformers_CVPR_2021_ paper.html 4 25. Wang, W., Xie, E., Li, X., Fan, D., Song, K., Liang, D., Lu, T., Luo, P., Shao, L.: Pyramid vision transformer: A versatile backbone for dense prediction without convolutions. CoRR abs/2102.12122 (2021), https://arxiv.org/abs/2102.12122 4 26. Wightman, R.: Pytorch image models. https://github.com/rwightman/ pytorch-image-models (2019). https://doi.org/10.5281/zenodo.4414861 10 27. Wu, D., Tang, Q., Zhao, Y., Zhang, M., Fu, Y., Zhang, D.: Easyquant: Posttraining quantization via scale optimization. CoRR abs/2006.16669 (2020), https://arxiv.org/abs/2006.16669 5, 6, 8, 12, 15 28. Zhang, D., Yang, J., Ye, D., Hua, G.: Lq-nets: Learned quantization for highly accurate and compact deep neural networks. In: Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y. (eds.) Computer Vision - ECCV 2018 - 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part VIII. Lecture Notes in Computer Science, vol. 11212, pp. 373– 390. Springer (2018). https://doi.org/10.1007/978-3-030-01237-3 23, https:// doi.org/10.1007/978-3-030-01237-3_23 2, 5</div><div class="divider" data-v-29962459></div><p class="review-content" data-v-29962459><span class="icon" data-v-29962459>answer:</span>PTQ4ViT: 트윈 균등 양자화를 사용한 비전 트랜스포머의 사후 훈련 양자화 저자: Zhihang Yuan 1, 3 ⋆, Chenhao Xue 1 ⋆, Yiqi Chen 1, Qiang Wu 3, Guangyu Sun 2 ⋆⋆ 1 Peking University 컴퓨터 과학 학교 2 Peking University 통합 회로 학교 3 Houmo AI 개요. 양자화는 신경망을 압축하는 가장 효과적인 방법 중 하나이며, 합성곱 신경망(CNN)에서 큰 성공을 거두었습니다. 최근 비전 트랜스포머는 컴퓨터 비전 분야에서 큰 잠재력을 보여주고 있습니다. 하지만 기존의 사후 훈련 양자화 방법은 비전 트랜스포머에서 성능이 좋지 않았으며, 8비트 양자화에서도 1% 이상의 정확도 저하가 발생했습니다. 따라서 우리는 비전 트랜스포머에서 양자화의 문제를 분석합니다. 소프트맥스와 GELU 함수 이후의 활성값 분포가 가우스 분포와 매우 다르다는 것을 관찰했습니다. 또한 MSE와 코사인 거리와 같은 일반적인 양자화 지표들이 최적 스케일링 인자를 결정하는 데 부정확하다는 것을 관찰했습니다. 본 논문에서는 이러한 활성값에 대한 양자화 오류를 줄이기 위해 트윈 균등 양자화 방법을 제안하고, 비용이 적게 드는 정확한 보정에 헤시안 가이드 메트릭을 사용할 것을 제안합니다. 비전 트랜스포머의 빠른 양자화를 가능하게 하기 위해, 우리는 효율적인 프레임워크인 PTQ4ViT를 개발했습니다. 실험에서 양자화된 비전 트랜스포머가 ImageNet 분류 작업에서 거의 손실 없는 예측 정확도를 달성했다는 것을 보여줍니다 (8비트 양자화에서 0.5% 미만의 감소). 이 논문에서 우리는 비전 트랜스포머에 대해 사후 훈련 양자화의 문제점을 발견하고, 이를 해결하기 위해 트윈 균등 양자화와 헤시안 가이드 메트릭을 제안합니다. PTQ4ViT 프레임워크를 개발하여 비전 트랜스포머의 빠른 양자화를 가능하게 하고, ImageNet 분류 작업에서 상당히 정확한 예측 결과를 달성하였습니다.</p></div></div><div class="poem-container" data-v-0ed6d867 data-v-29962459><div class="review" data-v-29962459><div class="review-title" data-v-29962459><span class="icon" data-v-29962459>question:</span>How much do CPAs make?</div><div class="divider" data-v-29962459></div><p class="review-content" data-v-29962459><span class="icon" data-v-29962459>answer:</span>The salary of Certified Public Accountants (CPAs) can vary widely depending on several factors such as location, experience, industry, and the size of the firm they work for. As of my last update in 2023, here are some general insights into CPA salaries: 1. Entry-level CPAs typically start at a lower range, which might be anywhere between 50,000 to 65,000 per year in the United States. This can depend on the cost of living in the area and the type of firm. 2. Mid-career CPAs with several years of experience and perhaps specialization in a particular area of accounting can earn salaries that range from 65,000 to over 100,000 per year. 3. Senior CPAs, especially those with management responsibilities or those who work for large accounting firms in high-cost living areas or industries like finance and tech, can earn well over 100,000. It&#39;s not uncommon for experienced CPAs in these roles to make 120,000 to 150,000 or more annually. 4. CPAs with additional credentials (such as those who are also Certified Information System Auditors or who have an MBA) or those in executive positions (like CFOs or Partners at accounting firms) could have salaries that exceed 200,000 per year. 5. CPAs working independently as consultants or owning their practices might have incomes that vary greatly based on client base, specialization, and success in business. It is important to note that the salary figures in the field of accounting are dynamic and change according to economic conditions, supply and demand for accounting professionals, and inflation. For the most up-to-date figures, it would be prudent to refer to salary surveys or databases, as well as job listings for CPAs in your targeted geographic area.</p></div></div><div class="poem-container" data-v-0ed6d867 data-v-29962459><div class="review" data-v-29962459><div class="review-title" data-v-29962459><span class="icon" data-v-29962459>question:</span>I’m a cpa, and those numbers are conservative but fairly accurate. I’m upset, however because this is not good money in 2023. Pre-Covid this was a stable career but post Covid you can’t afford anything on those salaries.</div><div class="divider" data-v-29962459></div><p class="review-content" data-v-29962459><span class="icon" data-v-29962459>answer:</span>It&#39;s understandable to feel frustrated if your salary isn&#39;t keeping pace with the cost of living or if it doesn&#39;t reflect the value you contribute, particularly given the extensive education, experience, and stringent licensing requirements needed to become a CPA. Several factors have brought significant changes to the job market and economic landscape since the onset of Covid-19, including: 1. **Inflation:** Many regions have seen inflation rates that outpace wage growth. This erodes purchasing power and can make salaries that were once considered good no longer sufficient to maintain the same standard of living. 2. **Remote Work:** The transition to more widespread remote work has changed the job market, leading some to expect higher salaries as companies save on office costs and seek to attract the best talent in a more competitive, location-agnostic environment. 3. **Economic Uncertainty:** Economic fluctuations and uncertainties can lead to reduced hiring, promotion freezes, or more cautious compensation growth strategies among employers. 4. **Industry Changes:** The accounting industry is evolving with automation and artificial intelligence streamlining or replacing some of the routine work traditionally done by accountants. This might put pressure on wages, especially for tasks that are becoming more standardized and less reliant on specialist expertise. If you feel that your compensation isn&#39;t sufficient, there are some paths you might consider to address this: - **Negotiating a Raise:** Prepare a case for higher pay based on your contributions, experience, and market rates for someone with your qualifications. - **Specializing:** CPAs with niche expertise in areas like forensic accounting, information systems, taxation, or other high-demand fields often command higher salaries. - **Changing Jobs:** Look for opportunities at other firms or industries that might offer higher pay or better benefits. - **Geographic Relocation:** Sometimes moving to a region with a lower cost of living or higher demand for CPAs can improve financial well-being. - **Additional Credentials or Education:** Additional certifications or a master&#39;s degree in a related field might open doors to higher-paying positions. - **Consulting or Freelancing:** Running your own consulting practice can sometimes lead to higher earnings, though it also comes with the risks and responsibilities of business ownership. It&#39;s important to also consider non-salary compensation, such as bonuses, profit-sharing, retirement plans, health benefits, and work-life balance, when evaluating your overall compensation package and job satisfaction.</p></div></div><div class="poem-container" data-v-0ed6d867 data-v-29962459><div class="review" data-v-29962459><div class="review-title" data-v-29962459><span class="icon" data-v-29962459>question:</span>Which of the following groupings of muscle type and their characteristics is INCORRECT? a. two sentences are incorrect b. Smooth, spindle shaped, involuntary c. Skeletal, striated, voluntary d. Cardiac, striated, voluntary</div><div class="divider" data-v-29962459></div><p class="review-content" data-v-29962459><span class="icon" data-v-29962459>answer:</span>d. Cardiac, striated, voluntary This is the incorrect statement. Cardiac muscle is indeed striated, like skeletal muscle, but it is involuntary, meaning it is not under conscious control. The heart muscle contracts automatically to pump blood without the need for us to think about it. Correct characteristics for each type of muscle tissue are as follows: - Smooth Muscle: spindle-shaped, involuntary, and is found in the walls of internal organs such as the stomach, intestines, and blood vessels. - Skeletal Muscle: striated, voluntary, and attached to the bones of the skeleton, thereby controlling body movement. - Cardiac Muscle: striated, involuntary, and found only in the heart. So, there is only one incorrect statement rather than two, which makes option &quot;a&quot; incorrect.</p></div></div><!--]--><!----></div><button class="load-more-button" data-v-0ed6d867><span data-v-0ed6d867>See more</span></button></section></div></div></main><!--[--><!--]--><div class="VPFooter" data-v-b0366457><p class="license" data-v-b0366457>Released under the <a class="vt-link link link" href="https://www.m44m.com" target="_blank" rel="noopener noreferrer" data-v-b0366457><!--[-->DeepMind License<!--]--><!----><!----></a>.</p><p class="copyright" data-v-b0366457>Copyright © 2014-2025 DeepMind</p></div><!--[--><!--]--></div></div><div class="visually-hidden" aria-live="polite" data-v-e4982c5a> has loaded</div></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about_coc.md\":\"B3ITOP5z\",\"about_community-guide.md\":\"Dvcdb1O6\",\"about_faq.md\":\"20McVa9n\",\"about_privacy.md\":\"CcWPOTgs\",\"about_releases.md\":\"GqqAVeGY\",\"about_team.md\":\"Bnw40y2b\",\"chatai_1.md\":\"BgB32TCh\",\"chatai_10.md\":\"3tu8vnRe\",\"chatai_11.md\":\"Dm3tjh6M\",\"chatai_12.md\":\"DtWJbP4K\",\"chatai_13.md\":\"Ny9An_ON\",\"chatai_14.md\":\"BbE9BZFk\",\"chatai_15.md\":\"m49wc5DT\",\"chatai_16.md\":\"D_YiSdyu\",\"chatai_17.md\":\"bg-ViBPK\",\"chatai_18.md\":\"DM3m8vFq\",\"chatai_19.md\":\"DPsoVwi4\",\"chatai_2.md\":\"ox6v_NJi\",\"chatai_20.md\":\"BrjItM5l\",\"chatai_21.md\":\"Uge6R4en\",\"chatai_22.md\":\"9rXeUXS9\",\"chatai_23.md\":\"DZgOOxrW\",\"chatai_24.md\":\"Ra8PenZq\",\"chatai_25.md\":\"DZQcdPfD\",\"chatai_26.md\":\"CKA96U6J\",\"chatai_27.md\":\"CTCtNxSV\",\"chatai_28.md\":\"CTaRQazx\",\"chatai_29.md\":\"BUs377WH\",\"chatai_3.md\":\"C-0TtaJS\",\"chatai_30.md\":\"BXIiSqZQ\",\"chatai_31.md\":\"COXtdHww\",\"chatai_32.md\":\"DKtTx2no\",\"chatai_33.md\":\"JPKCrACi\",\"chatai_34.md\":\"BctSmPQH\",\"chatai_35.md\":\"BM4YkKru\",\"chatai_36.md\":\"CGh41Ol4\",\"chatai_37.md\":\"tgV3t9UK\",\"chatai_38.md\":\"Badr2xqw\",\"chatai_39.md\":\"DSQ-V-ww\",\"chatai_4.md\":\"eH10d5sI\",\"chatai_40.md\":\"DFUp2M7g\",\"chatai_41.md\":\"S1a2JCu1\",\"chatai_42.md\":\"CmA0NkRm\",\"chatai_43.md\":\"CieVdmnd\",\"chatai_44.md\":\"BGbtZudD\",\"chatai_45.md\":\"Dmd8q9aE\",\"chatai_46.md\":\"Dd-etuyE\",\"chatai_47.md\":\"T2nj0yAA\",\"chatai_48.md\":\"BlMXwT9m\",\"chatai_49.md\":\"DC0L12Le\",\"chatai_5.md\":\"Xv3S3yXd\",\"chatai_50.md\":\"Qvx8nlt7\",\"chatai_51.md\":\"ESe-am3X\",\"chatai_52.md\":\"BzA7fXlV\",\"chatai_53.md\":\"DIYsBV8a\",\"chatai_54.md\":\"wHO9NN3F\",\"chatai_55.md\":\"fxV7ZqIG\",\"chatai_56.md\":\"Ce4MVmeF\",\"chatai_57.md\":\"CoCoz11z\",\"chatai_58.md\":\"C0ljxhzn\",\"chatai_59.md\":\"BGN5JH9o\",\"chatai_6.md\":\"CfZpgWMI\",\"chatai_60.md\":\"4x4OmnIV\",\"chatai_61.md\":\"-cc7OBgU\",\"chatai_62.md\":\"D977Ja25\",\"chatai_63.md\":\"BEzMQUfz\",\"chatai_64.md\":\"BHXM56Q1\",\"chatai_65.md\":\"BC5iPG1s\",\"chatai_66.md\":\"CALgxGZF\",\"chatai_67.md\":\"D777loZW\",\"chatai_68.md\":\"DpgdX1md\",\"chatai_7.md\":\"BC2ysiae\",\"chatai_8.md\":\"C7bTMljZ\",\"chatai_9.md\":\"B2Kcqjzf\",\"chatai_index.md\":\"hL1i_FIH\",\"deepseek_1.md\":\"DTvQbkuc\",\"deepseek_10.md\":\"DH85EAM-\",\"deepseek_11.md\":\"F_bayQ6D\",\"deepseek_12.md\":\"usWKjSTD\",\"deepseek_13.md\":\"C5vbl1Pm\",\"deepseek_14.md\":\"CyAIFkKB\",\"deepseek_15.md\":\"B8r1KFn6\",\"deepseek_16.md\":\"Vr9q2BWt\",\"deepseek_17.md\":\"Bcbs5HsI\",\"deepseek_18.md\":\"BT9XKrVh\",\"deepseek_19.md\":\"CrZl_ygr\",\"deepseek_2.md\":\"bglTK7lE\",\"deepseek_20.md\":\"Cd3sj7zu\",\"deepseek_21.md\":\"KuBIkkSn\",\"deepseek_22.md\":\"CaypC_Bj\",\"deepseek_23.md\":\"DZi6ZEWd\",\"deepseek_24.md\":\"B8xdaAkZ\",\"deepseek_25.md\":\"DTfwIlQk\",\"deepseek_26.md\":\"CKfZhVpU\",\"deepseek_27.md\":\"CWTxQB8L\",\"deepseek_28.md\":\"CZDHHLll\",\"deepseek_29.md\":\"CMHknxHX\",\"deepseek_3.md\":\"RtsiDS2-\",\"deepseek_30.md\":\"BjIsS7Ln\",\"deepseek_31.md\":\"Dfmen721\",\"deepseek_32.md\":\"Bj4NETT8\",\"deepseek_33.md\":\"CmKSTkYU\",\"deepseek_34.md\":\"DfGkMlKT\",\"deepseek_35.md\":\"BD7fmxbp\",\"deepseek_36.md\":\"42yChlzI\",\"deepseek_37.md\":\"DvOkdcpV\",\"deepseek_38.md\":\"DVaUKKTP\",\"deepseek_39.md\":\"CkYc7Ntl\",\"deepseek_4.md\":\"BNti_4jc\",\"deepseek_40.md\":\"Cw_W1Zvo\",\"deepseek_41.md\":\"D-Q0-b9C\",\"deepseek_42.md\":\"m6zCXU1D\",\"deepseek_43.md\":\"CXWQv2op\",\"deepseek_44.md\":\"Da9X4ERw\",\"deepseek_45.md\":\"CUvoTgEH\",\"deepseek_46.md\":\"DcyErygc\",\"deepseek_47.md\":\"eJ0PZ-yZ\",\"deepseek_48.md\":\"CF1hgDfK\",\"deepseek_49.md\":\"tfK_-OBB\",\"deepseek_5.md\":\"1Q8gWW0-\",\"deepseek_50.md\":\"BmJi18XV\",\"deepseek_51.md\":\"BZOZIfs1\",\"deepseek_52.md\":\"DGEvGsV8\",\"deepseek_53.md\":\"BTyLDcbh\",\"deepseek_54.md\":\"DKqIn-S6\",\"deepseek_55.md\":\"CPBPEVKW\",\"deepseek_56.md\":\"ljmO_AVb\",\"deepseek_57.md\":\"BcyrXIzA\",\"deepseek_58.md\":\"CnOkqxvV\",\"deepseek_59.md\":\"4XC3ALW9\",\"deepseek_6.md\":\"D9H-BrMb\",\"deepseek_60.md\":\"BmgA2VH7\",\"deepseek_61.md\":\"DarYked4\",\"deepseek_62.md\":\"J1bzBa_R\",\"deepseek_63.md\":\"DN86DSIn\",\"deepseek_64.md\":\"Dcc9ZyeJ\",\"deepseek_65.md\":\"DMXmeraW\",\"deepseek_66.md\":\"BnIrqbra\",\"deepseek_67.md\":\"BOy03Ogx\",\"deepseek_68.md\":\"D8k71kQX\",\"deepseek_7.md\":\"DSnu6kwH\",\"deepseek_8.md\":\"C1lU59Se\",\"deepseek_9.md\":\"lE0Tc1XW\",\"drive_1.md\":\"y9zqeJLb\",\"drive_10.md\":\"BJ-jrTZ2\",\"drive_11.md\":\"D7EAoWQJ\",\"drive_12.md\":\"CchtPtUT\",\"drive_13.md\":\"CShUTOCZ\",\"drive_14.md\":\"oTajGhQn\",\"drive_15.md\":\"BWm1N_wU\",\"drive_16.md\":\"BZOkvR59\",\"drive_17.md\":\"GFMoceCO\",\"drive_18.md\":\"Cbbhm_mT\",\"drive_19.md\":\"CE4SGiDH\",\"drive_2.md\":\"DusjtGOq\",\"drive_20.md\":\"CCWUg7Db\",\"drive_21.md\":\"DYl8a-ew\",\"drive_22.md\":\"I5vm5pCo\",\"drive_23.md\":\"D5D1M_oo\",\"drive_24.md\":\"Ddqbrr-R\",\"drive_25.md\":\"C2GqnrIN\",\"drive_26.md\":\"CTEn9UoG\",\"drive_27.md\":\"CVyuY3JO\",\"drive_28.md\":\"BkyMb5vG\",\"drive_29.md\":\"CbBayKkC\",\"drive_3.md\":\"BsbZk3ZA\",\"drive_30.md\":\"JhyHW0ck\",\"drive_31.md\":\"Dfa-fSGK\",\"drive_32.md\":\"CRikB3Tb\",\"drive_33.md\":\"DYI1yQ10\",\"drive_34.md\":\"Bd_2rLlc\",\"drive_35.md\":\"6tc-pgTC\",\"drive_36.md\":\"B2DJ9LdI\",\"drive_37.md\":\"CfEGpzNQ\",\"drive_38.md\":\"BPlNfW_R\",\"drive_39.md\":\"Bw6pnS2f\",\"drive_4.md\":\"CNfwyEGU\",\"drive_40.md\":\"CAN0kFrx\",\"drive_41.md\":\"CfxuK4Bi\",\"drive_42.md\":\"B7pSyCb3\",\"drive_43.md\":\"-ntvpjGV\",\"drive_44.md\":\"Da9Somu6\",\"drive_45.md\":\"B1Sy3_e3\",\"drive_46.md\":\"fnU7lut3\",\"drive_47.md\":\"DYErJJYA\",\"drive_48.md\":\"NTotJTRF\",\"drive_49.md\":\"E8y8wUgC\",\"drive_5.md\":\"D1SNNlgy\",\"drive_50.md\":\"CTkugyYO\",\"drive_51.md\":\"Bfy04eF-\",\"drive_52.md\":\"DssTp3VO\",\"drive_53.md\":\"Cr4Df5Tx\",\"drive_54.md\":\"BVVGq49B\",\"drive_55.md\":\"DO8lREq5\",\"drive_56.md\":\"DxXQ3IrP\",\"drive_57.md\":\"HpGhrZuq\",\"drive_58.md\":\"CREpV2Bv\",\"drive_59.md\":\"B_5VNO-6\",\"drive_6.md\":\"D2wVXkNU\",\"drive_60.md\":\"Pd_O_k1I\",\"drive_7.md\":\"DL6KOlOn\",\"drive_8.md\":\"CmicSA5q\",\"drive_9.md\":\"C3rF2Kr-\",\"drive_donation.md\":\"8wvNJAVf\",\"drive_prompt.md\":\"DuFBIqs0\",\"drive_promptlibrary.md\":\"D2zvzxSB\",\"drive_team.md\":\"CkNmWMDG\",\"ecosystem_deepseek.md\":\"BU8mlKeX\",\"ecosystem_navigation.md\":\"wKlND_1J\",\"ecosystem_newsletters.md\":\"BhroXMnV\",\"ecosystem_themes.md\":\"DcxYtm4j\",\"error-reference_index.md\":\"C8cWCSv1\",\"examples_index.md\":\"DYIYBDwT\",\"grok_1.md\":\"BHED4CkF\",\"grok_10.md\":\"xGBqRu0m\",\"grok_11.md\":\"CXxZTZz9\",\"grok_12.md\":\"BuF3UU1I\",\"grok_13.md\":\"7DhVPntI\",\"grok_14.md\":\"B2NPGNH0\",\"grok_15.md\":\"ZKoQH8IA\",\"grok_16.md\":\"yh8nCp3m\",\"grok_17.md\":\"BXmzpxJm\",\"grok_18.md\":\"BtFHGZfI\",\"grok_19.md\":\"8N5f7GRP\",\"grok_2.md\":\"sAUjlm5v\",\"grok_20.md\":\"TWVB-kST\",\"grok_21.md\":\"TLC_wHsk\",\"grok_22.md\":\"DJE7-82G\",\"grok_23.md\":\"ClO4b4RL\",\"grok_24.md\":\"CrsoXWM3\",\"grok_25.md\":\"B5B502iZ\",\"grok_26.md\":\"C7VeSuqY\",\"grok_27.md\":\"Bu7oFB7O\",\"grok_28.md\":\"dPe15WHr\",\"grok_29.md\":\"BC67mA5F\",\"grok_3.md\":\"Dd0tGOWY\",\"grok_30.md\":\"BnvRClgT\",\"grok_31.md\":\"_PgcWNam\",\"grok_32.md\":\"CB_3CbyB\",\"grok_33.md\":\"EN3xUzoU\",\"grok_34.md\":\"C4muBi4o\",\"grok_35.md\":\"BoMYfDTy\",\"grok_36.md\":\"lXCJK2Ey\",\"grok_37.md\":\"CVozi6N9\",\"grok_38.md\":\"BT_HuraQ\",\"grok_39.md\":\"DskwTcc9\",\"grok_4.md\":\"1cgspvPG\",\"grok_40.md\":\"YRnS9Kkm\",\"grok_41.md\":\"Dt0oz5tv\",\"grok_42.md\":\"zBPNgNWl\",\"grok_43.md\":\"BT4XJ5Oq\",\"grok_44.md\":\"BHATJ3Dc\",\"grok_45.md\":\"WDqOXgxW\",\"grok_46.md\":\"CqHvH-ZE\",\"grok_47.md\":\"7c0BE36X\",\"grok_48.md\":\"c2fou_2E\",\"grok_49.md\":\"C5teWW5p\",\"grok_5.md\":\"D98ZzxJd\",\"grok_50.md\":\"DFPN_LDJ\",\"grok_51.md\":\"Cvs6v6Vp\",\"grok_52.md\":\"DMizCPzZ\",\"grok_53.md\":\"DMuHsnqO\",\"grok_54.md\":\"Cs7mgZND\",\"grok_55.md\":\"6ySMNJsd\",\"grok_56.md\":\"BmemxBOh\",\"grok_57.md\":\"iWaKZD99\",\"grok_58.md\":\"DB9cw9Zh\",\"grok_59.md\":\"CBTFRbCF\",\"grok_6.md\":\"D8kqmVXe\",\"grok_60.md\":\"prccvtPU\",\"grok_61.md\":\"Dkptqa81\",\"grok_62.md\":\"BVWAUs7k\",\"grok_63.md\":\"gbFaTilP\",\"grok_64.md\":\"jXTUVf6E\",\"grok_65.md\":\"GVvahJVB\",\"grok_66.md\":\"Bl0iquLF\",\"grok_67.md\":\"BJ-cTsd1\",\"grok_68.md\":\"nUTGGveN\",\"grok_7.md\":\"BeJZN_bK\",\"grok_8.md\":\"CXpeqMJt\",\"grok_9.md\":\"BqW53ZgE\",\"guide_1.md\":\"d1L_DuzK\",\"guide_10.md\":\"DQGsIrd6\",\"guide_11.md\":\"FS685p7d\",\"guide_12.md\":\"B153Hlsv\",\"guide_13.md\":\"CSCvmzHJ\",\"guide_14.md\":\"CulLADEH\",\"guide_15.md\":\"BMVoPB2o\",\"guide_16.md\":\"Bsd9-tAy\",\"guide_17.md\":\"BsATzWh8\",\"guide_18.md\":\"Lj8BVsR3\",\"guide_19.md\":\"BtYc5JjA\",\"guide_2.md\":\"DPcnyeJu\",\"guide_20.md\":\"DETanLds\",\"guide_21.md\":\"Ctz4gTqo\",\"guide_22.md\":\"e7TuLOCp\",\"guide_23.md\":\"DPmAUOfR\",\"guide_24.md\":\"DkGr4QpU\",\"guide_25.md\":\"DvB1984u\",\"guide_26.md\":\"C0gILsdR\",\"guide_27.md\":\"CpOyf6-C\",\"guide_28.md\":\"jhRz8ZlS\",\"guide_29.md\":\"BsRTS28J\",\"guide_3.md\":\"nm4UblQo\",\"guide_30.md\":\"DAKxpkA6\",\"guide_31.md\":\"BuMXxQMJ\",\"guide_32.md\":\"R7TYliN6\",\"guide_33.md\":\"B419SWlV\",\"guide_34.md\":\"B0oImByT\",\"guide_35.md\":\"D5f3_qL9\",\"guide_36.md\":\"C7SSMo6J\",\"guide_37.md\":\"Dm7oEUdL\",\"guide_38.md\":\"EKIFwjz9\",\"guide_39.md\":\"Y2iuj7Gc\",\"guide_4.md\":\"VdltCViw\",\"guide_40.md\":\"E67VmSvD\",\"guide_41.md\":\"BFPhTcwx\",\"guide_42.md\":\"DxdxJTDK\",\"guide_43.md\":\"RTYbZmuE\",\"guide_44.md\":\"yqvwGqUV\",\"guide_45.md\":\"B_WU4AgC\",\"guide_46.md\":\"D3yhbIF9\",\"guide_47.md\":\"DFGBUugz\",\"guide_48.md\":\"BiZSbP8x\",\"guide_49.md\":\"CizU8hk6\",\"guide_5.md\":\"DHT6UoaD\",\"guide_50.md\":\"DhpxpKMX\",\"guide_51.md\":\"DSLRPyio\",\"guide_52.md\":\"qsz_rInk\",\"guide_53.md\":\"ClIP7UC8\",\"guide_54.md\":\"BNWFgixm\",\"guide_55.md\":\"Cf0vi-nC\",\"guide_56.md\":\"DMctCb4-\",\"guide_57.md\":\"NnnXC0JC\",\"guide_58.md\":\"DBPD-g_u\",\"guide_59.md\":\"ESKq5LoQ\",\"guide_6.md\":\"D1xyoxIE\",\"guide_60.md\":\"Bg64_WRw\",\"guide_61.md\":\"D2u8ti7u\",\"guide_62.md\":\"BgmRD6zV\",\"guide_63.md\":\"Bh5Ym34y\",\"guide_64.md\":\"DBoXN8NL\",\"guide_65.md\":\"BRJsdUAN\",\"guide_66.md\":\"D9my8mmd\",\"guide_67.md\":\"RLJXbCLt\",\"guide_68.md\":\"B9xW4Nmu\",\"guide_7.md\":\"DBQHrtE7\",\"guide_8.md\":\"SIqrc9MU\",\"guide_9.md\":\"EKtc47a9\",\"index.md\":\"DUAjWfku\",\"library_1.md\":\"BAPJF_Wn\",\"library_10.md\":\"DGqehvqI\",\"library_11.md\":\"EBahyiNm\",\"library_12.md\":\"DkKWtoEd\",\"library_13.md\":\"5wWBdVWo\",\"library_14.md\":\"DXQxitp-\",\"library_15.md\":\"1XqPYqCa\",\"library_16.md\":\"DcTOLgPh\",\"library_17.md\":\"BJTvepKL\",\"library_18.md\":\"DpAB3z7i\",\"library_19.md\":\"BIyk0Q85\",\"library_2.md\":\"BKUoIHN0\",\"library_20.md\":\"CRnSyc9u\",\"library_21.md\":\"gEA8AR4G\",\"library_22.md\":\"Beomnrig\",\"library_23.md\":\"Dc1Oz_pW\",\"library_24.md\":\"DpbzLA0m\",\"library_25.md\":\"DLBsr-lW\",\"library_26.md\":\"C7mMhLdJ\",\"library_27.md\":\"BkG-JzHf\",\"library_28.md\":\"CN2aw1DK\",\"library_29.md\":\"DLkjhCK6\",\"library_3.md\":\"C3H-ivYf\",\"library_30.md\":\"D0PXjoza\",\"library_31.md\":\"BMKviSpR\",\"library_32.md\":\"C99mZxww\",\"library_33.md\":\"Bmd3I-_4\",\"library_34.md\":\"gF2xsf_u\",\"library_35.md\":\"DC060IrM\",\"library_36.md\":\"Cc5-BE01\",\"library_37.md\":\"CkgvxaGO\",\"library_38.md\":\"DBzYPM49\",\"library_39.md\":\"DATcTyIt\",\"library_4.md\":\"CMPh4FkT\",\"library_40.md\":\"Cf6mv0jY\",\"library_41.md\":\"DPPW1jbk\",\"library_42.md\":\"DZyz1krS\",\"library_43.md\":\"4D1cdScF\",\"library_44.md\":\"DfKYE339\",\"library_45.md\":\"CfWMl0IR\",\"library_46.md\":\"CesjjCo6\",\"library_47.md\":\"D8W-nFbK\",\"library_48.md\":\"DWKIGtMd\",\"library_49.md\":\"BoaHxUBK\",\"library_5.md\":\"CSv6ziMc\",\"library_50.md\":\"_I8g2Ubm\",\"library_51.md\":\"DR3ydZFl\",\"library_52.md\":\"DNxqQVfV\",\"library_53.md\":\"BSF5Tw1s\",\"library_54.md\":\"Dp7koI7B\",\"library_55.md\":\"COdW6YYx\",\"library_56.md\":\"CJYGJxcM\",\"library_57.md\":\"QvGyIVAb\",\"library_58.md\":\"CXyQ_-Ox\",\"library_59.md\":\"BWOUgj8V\",\"library_6.md\":\"CBA91VE4\",\"library_60.md\":\"Dp6dz-PT\",\"library_61.md\":\"1-EBj2uT\",\"library_62.md\":\"Bh-l34MO\",\"library_63.md\":\"DhKr0a0X\",\"library_64.md\":\"9lzbi1FF\",\"library_65.md\":\"B_xkIysk\",\"library_66.md\":\"mh4kYbHO\",\"library_67.md\":\"DMezKc7u\",\"library_68.md\":\"CHWI8kb1\",\"library_7.md\":\"D8iCd4mR\",\"library_8.md\":\"CkckdGiD\",\"library_9.md\":\"CGBrtDyR\",\"partners_all.md\":\"DrI_oKr-\",\"partners_curotec.md\":\"C5GS61rR\",\"partners_herodevs.md\":\"BVDxGK-m\",\"partners_index.md\":\"BBcUVcAI\",\"partners_monterail.md\":\"B627I69r\",\"partners_passionatepeople.md\":\"BDAHuxir\",\"partners_redberry.md\":\"B-Sf3MRF\",\"partners_vehikl.md\":\"CjJYaD5l\",\"partners_webreinvent.md\":\"CuHjowhF\",\"quotes_1.md\":\"D2q9XqOs\",\"quotes_10.md\":\"MTUOWIGN\",\"quotes_11.md\":\"CRSDFLKG\",\"quotes_12.md\":\"BjoKaqof\",\"quotes_13.md\":\"Cw2SkwV_\",\"quotes_14.md\":\"DM27Yyea\",\"quotes_15.md\":\"DCPIoRn4\",\"quotes_16.md\":\"BRyK1fwI\",\"quotes_17.md\":\"Df_nmMM7\",\"quotes_18.md\":\"tdnRTKjk\",\"quotes_19.md\":\"C3zwe6vj\",\"quotes_2.md\":\"Bp1YYo-c\",\"quotes_20.md\":\"Dy39d7Nr\",\"quotes_21.md\":\"C85jV7y3\",\"quotes_22.md\":\"DVm9jdKv\",\"quotes_23.md\":\"BTLCOk4l\",\"quotes_24.md\":\"72oQlrN0\",\"quotes_25.md\":\"C9rF9wlo\",\"quotes_26.md\":\"9w9GvcrM\",\"quotes_27.md\":\"Dow-v5yD\",\"quotes_28.md\":\"8tWCH8s1\",\"quotes_29.md\":\"DzAgN0W4\",\"quotes_3.md\":\"CgjwfhOz\",\"quotes_30.md\":\"DyHtKSBv\",\"quotes_31.md\":\"iWfrF2ot\",\"quotes_32.md\":\"Bro84Xwy\",\"quotes_33.md\":\"DPpNaZC1\",\"quotes_34.md\":\"C13n_O6P\",\"quotes_35.md\":\"B_JYfr5c\",\"quotes_36.md\":\"DJU7tRKi\",\"quotes_37.md\":\"a0xA9SEZ\",\"quotes_38.md\":\"iZRJz6_V\",\"quotes_39.md\":\"CqjZXDpG\",\"quotes_4.md\":\"Oc6LxEqb\",\"quotes_40.md\":\"BMicAZ2p\",\"quotes_41.md\":\"DniHBH6x\",\"quotes_42.md\":\"DN5YOAvK\",\"quotes_43.md\":\"C2h3ZVGr\",\"quotes_44.md\":\"BxwSbWrD\",\"quotes_45.md\":\"sro4WLsw\",\"quotes_46.md\":\"D5L43sfm\",\"quotes_47.md\":\"_Z8bZazu\",\"quotes_48.md\":\"BUNCqClQ\",\"quotes_49.md\":\"BpMVCO-0\",\"quotes_5.md\":\"LGSEj6cg\",\"quotes_50.md\":\"Cb2HhOnx\",\"quotes_51.md\":\"Dds0dm_B\",\"quotes_52.md\":\"DInUakFa\",\"quotes_53.md\":\"B41Q3t8N\",\"quotes_54.md\":\"D-KCAa2p\",\"quotes_55.md\":\"DdaL2XiU\",\"quotes_56.md\":\"2_gBDdun\",\"quotes_57.md\":\"CfCGq9Bi\",\"quotes_58.md\":\"CNc_F8wo\",\"quotes_59.md\":\"C4vFLL_g\",\"quotes_6.md\":\"gSTw9fWY\",\"quotes_60.md\":\"QjQVvTDS\",\"quotes_61.md\":\"ClzDfLeg\",\"quotes_62.md\":\"Bbk-DrH5\",\"quotes_63.md\":\"DrltkBas\",\"quotes_64.md\":\"Dn23QpGt\",\"quotes_65.md\":\"DNrKHFA_\",\"quotes_66.md\":\"B-hGUcvF\",\"quotes_67.md\":\"DAsvMFOx\",\"quotes_68.md\":\"zfo6WYld\",\"quotes_7.md\":\"CWq2ZEJx\",\"quotes_8.md\":\"CNgZ5vVx\",\"quotes_9.md\":\"C3eHkpv9\",\"swap_app.md\":\"dX62wfc0\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh\",\"dir\":\"ltr\",\"title\":\"DeepMind\",\"description\":\"DeepMind\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"logo\":\"/images/logo.svg\",\"nav\":[{\"text\":\"data\",\"activeMatch\":\"^/drive/\",\"items\":[{\"text\":\"data1\",\"link\":\"/drive/1\"},{\"text\":\"data2\",\"link\":\"/drive/2\"},{\"text\":\"data3\",\"link\":\"/drive/3\"},{\"text\":\"data4\",\"link\":\"/drive/4\"},{\"text\":\"data5\",\"link\":\"/drive/5\"},{\"text\":\"data6\",\"link\":\"/drive/6\"},{\"text\":\"data7\",\"link\":\"/drive/7\"},{\"text\":\"data8\",\"link\":\"/drive/8\"},{\"text\":\"data9\",\"link\":\"/drive/9\"},{\"text\":\"data10\",\"link\":\"/drive/10\"},{\"text\":\"data11\",\"link\":\"/drive/11\"},{\"text\":\"data12\",\"link\":\"/drive/12\"},{\"text\":\"data13\",\"link\":\"/drive/13\"},{\"text\":\"data14\",\"link\":\"/drive/14\"},{\"text\":\"data15\",\"link\":\"/drive/15\"},{\"text\":\"data16\",\"link\":\"/drive/16\"},{\"text\":\"data17\",\"link\":\"/drive/17\"},{\"text\":\"data18\",\"link\":\"/drive/18\"},{\"text\":\"data19\",\"link\":\"/drive/19\"},{\"text\":\"data20\",\"link\":\"/drive/20\"},{\"text\":\"data21\",\"link\":\"/drive/21\"},{\"text\":\"data22\",\"link\":\"/drive/22\"},{\"text\":\"data23\",\"link\":\"/drive/23\"},{\"text\":\"data24\",\"link\":\"/drive/24\"},{\"text\":\"data25\",\"link\":\"/drive/25\"},{\"text\":\"data26\",\"link\":\"/drive/26\"},{\"text\":\"data27\",\"link\":\"/drive/27\"},{\"text\":\"data28\",\"link\":\"/drive/28\"},{\"text\":\"data29\",\"link\":\"/drive/29\"},{\"text\":\"data30\",\"link\":\"/drive/30\"},{\"text\":\"data31\",\"link\":\"/drive/31\"},{\"text\":\"data32\",\"link\":\"/drive/32\"},{\"text\":\"data33\",\"link\":\"/drive/33\"},{\"text\":\"data34\",\"link\":\"/drive/34\"},{\"text\":\"data35\",\"link\":\"/drive/35\"},{\"text\":\"data36\",\"link\":\"/drive/36\"},{\"text\":\"data37\",\"link\":\"/drive/37\"},{\"text\":\"data38\",\"link\":\"/drive/38\"},{\"text\":\"data39\",\"link\":\"/drive/39\"},{\"text\":\"data40\",\"link\":\"/drive/40\"},{\"text\":\"data41\",\"link\":\"/drive/41\"},{\"text\":\"data42\",\"link\":\"/drive/42\"},{\"text\":\"data43\",\"link\":\"/drive/43\"},{\"text\":\"data44\",\"link\":\"/drive/44\"},{\"text\":\"data45\",\"link\":\"/drive/45\"},{\"text\":\"data46\",\"link\":\"/drive/46\"},{\"text\":\"data47\",\"link\":\"/drive/47\"},{\"text\":\"data48\",\"link\":\"/drive/48\"},{\"text\":\"data49\",\"link\":\"/drive/49\"},{\"text\":\"data50\",\"link\":\"/drive/50\"},{\"text\":\"data51\",\"link\":\"/drive/51\"},{\"text\":\"data52\",\"link\":\"/drive/52\"},{\"text\":\"data53\",\"link\":\"/drive/53\"},{\"text\":\"data54\",\"link\":\"/drive/54\"},{\"text\":\"data55\",\"link\":\"/drive/55\"},{\"text\":\"data56\",\"link\":\"/drive/56\"},{\"text\":\"data57\",\"link\":\"/drive/57\"},{\"text\":\"data58\",\"link\":\"/drive/58\"},{\"text\":\"data59\",\"link\":\"/drive/59\"},{\"text\":\"data60\",\"link\":\"/drive/60\"}]},{\"text\":\"grok\",\"activeMatch\":\"^/grok/\",\"items\":[{\"text\":\"grok1\",\"link\":\"/grok/1\"},{\"text\":\"grok2\",\"link\":\"/grok/2\"},{\"text\":\"grok3\",\"link\":\"/grok/3\"},{\"text\":\"grok4\",\"link\":\"/grok/4\"},{\"text\":\"grok5\",\"link\":\"/grok/5\"},{\"text\":\"grok6\",\"link\":\"/grok/6\"},{\"text\":\"grok7\",\"link\":\"/grok/7\"},{\"text\":\"grok8\",\"link\":\"/grok/8\"},{\"text\":\"grok9\",\"link\":\"/grok/9\"},{\"text\":\"grok10\",\"link\":\"/grok/10\"},{\"text\":\"grok11\",\"link\":\"/grok/11\"},{\"text\":\"grok12\",\"link\":\"/grok/12\"},{\"text\":\"grok13\",\"link\":\"/grok/13\"},{\"text\":\"grok14\",\"link\":\"/grok/14\"},{\"text\":\"grok15\",\"link\":\"/grok/15\"},{\"text\":\"grok16\",\"link\":\"/grok/16\"},{\"text\":\"grok17\",\"link\":\"/grok/17\"},{\"text\":\"grok18\",\"link\":\"/grok/18\"},{\"text\":\"grok19\",\"link\":\"/grok/19\"},{\"text\":\"grok20\",\"link\":\"/grok/20\"},{\"text\":\"grok21\",\"link\":\"/grok/21\"},{\"text\":\"grok22\",\"link\":\"/grok/22\"},{\"text\":\"grok23\",\"link\":\"/grok/23\"},{\"text\":\"grok24\",\"link\":\"/grok/24\"},{\"text\":\"grok25\",\"link\":\"/grok/25\"},{\"text\":\"grok26\",\"link\":\"/grok/26\"},{\"text\":\"grok27\",\"link\":\"/grok/27\"},{\"text\":\"grok28\",\"link\":\"/grok/28\"},{\"text\":\"grok29\",\"link\":\"/grok/29\"},{\"text\":\"grok30\",\"link\":\"/grok/30\"},{\"text\":\"grok31\",\"link\":\"/grok/31\"},{\"text\":\"grok32\",\"link\":\"/grok/32\"},{\"text\":\"grok33\",\"link\":\"/grok/33\"},{\"text\":\"grok34\",\"link\":\"/grok/34\"},{\"text\":\"grok35\",\"link\":\"/grok/35\"},{\"text\":\"grok36\",\"link\":\"/grok/36\"},{\"text\":\"grok37\",\"link\":\"/grok/37\"},{\"text\":\"grok38\",\"link\":\"/grok/38\"},{\"text\":\"grok39\",\"link\":\"/grok/39\"},{\"text\":\"grok40\",\"link\":\"/grok/40\"},{\"text\":\"grok41\",\"link\":\"/grok/41\"},{\"text\":\"grok42\",\"link\":\"/grok/42\"},{\"text\":\"grok43\",\"link\":\"/grok/43\"},{\"text\":\"grok44\",\"link\":\"/grok/44\"},{\"text\":\"grok45\",\"link\":\"/grok/45\"},{\"text\":\"grok46\",\"link\":\"/grok/46\"},{\"text\":\"grok47\",\"link\":\"/grok/47\"},{\"text\":\"grok48\",\"link\":\"/grok/48\"},{\"text\":\"grok49\",\"link\":\"/grok/49\"},{\"text\":\"grok50\",\"link\":\"/grok/50\"},{\"text\":\"grok51\",\"link\":\"/grok/51\"},{\"text\":\"grok52\",\"link\":\"/grok/52\"},{\"text\":\"grok53\",\"link\":\"/grok/53\"},{\"text\":\"grok54\",\"link\":\"/grok/54\"},{\"text\":\"grok55\",\"link\":\"/grok/55\"},{\"text\":\"grok56\",\"link\":\"/grok/56\"},{\"text\":\"grok57\",\"link\":\"/grok/57\"},{\"text\":\"grok58\",\"link\":\"/grok/58\"},{\"text\":\"grok59\",\"link\":\"/grok/59\"},{\"text\":\"grok60\",\"link\":\"/grok/60\"},{\"text\":\"grok61\",\"link\":\"/grok/61\"},{\"text\":\"grok62\",\"link\":\"/grok/62\"},{\"text\":\"grok63\",\"link\":\"/grok/63\"},{\"text\":\"grok64\",\"link\":\"/grok/64\"},{\"text\":\"grok65\",\"link\":\"/grok/65\"},{\"text\":\"grok66\",\"link\":\"/grok/66\"},{\"text\":\"grok67\",\"link\":\"/grok/67\"},{\"text\":\"grok68\",\"link\":\"/grok/68\"}]},{\"text\":\"wiki\",\"activeMatch\":\"^/guide/\",\"items\":[{\"text\":\"wiki1\",\"link\":\"/guide/1\"},{\"text\":\"wiki2\",\"link\":\"/guide/2\"},{\"text\":\"wiki3\",\"link\":\"/guide/3\"},{\"text\":\"wiki4\",\"link\":\"/guide/4\"},{\"text\":\"wiki5\",\"link\":\"/guide/5\"},{\"text\":\"wiki6\",\"link\":\"/guide/6\"},{\"text\":\"wiki7\",\"link\":\"/guide/7\"},{\"text\":\"wiki8\",\"link\":\"/guide/8\"},{\"text\":\"wiki9\",\"link\":\"/guide/9\"},{\"text\":\"wiki10\",\"link\":\"/guide/10\"},{\"text\":\"wiki11\",\"link\":\"/guide/11\"},{\"text\":\"wiki12\",\"link\":\"/guide/12\"},{\"text\":\"wiki13\",\"link\":\"/guide/13\"},{\"text\":\"wiki14\",\"link\":\"/guide/14\"},{\"text\":\"wiki15\",\"link\":\"/guide/15\"},{\"text\":\"wiki16\",\"link\":\"/guide/16\"},{\"text\":\"wiki17\",\"link\":\"/guide/17\"},{\"text\":\"wiki18\",\"link\":\"/guide/18\"},{\"text\":\"wiki19\",\"link\":\"/guide/19\"},{\"text\":\"wiki20\",\"link\":\"/guide/20\"},{\"text\":\"wiki21\",\"link\":\"/guide/21\"},{\"text\":\"wiki22\",\"link\":\"/guide/22\"},{\"text\":\"wiki23\",\"link\":\"/guide/23\"},{\"text\":\"wiki24\",\"link\":\"/guide/24\"},{\"text\":\"wiki25\",\"link\":\"/guide/25\"},{\"text\":\"wiki26\",\"link\":\"/guide/26\"},{\"text\":\"wiki27\",\"link\":\"/guide/27\"},{\"text\":\"wiki28\",\"link\":\"/guide/28\"},{\"text\":\"wiki29\",\"link\":\"/guide/29\"},{\"text\":\"wiki30\",\"link\":\"/guide/30\"},{\"text\":\"wiki31\",\"link\":\"/guide/31\"},{\"text\":\"wiki32\",\"link\":\"/guide/32\"},{\"text\":\"wiki33\",\"link\":\"/guide/33\"},{\"text\":\"wiki34\",\"link\":\"/guide/34\"},{\"text\":\"wiki35\",\"link\":\"/guide/35\"},{\"text\":\"wiki36\",\"link\":\"/guide/36\"},{\"text\":\"wiki37\",\"link\":\"/guide/37\"},{\"text\":\"wiki38\",\"link\":\"/guide/38\"},{\"text\":\"wiki39\",\"link\":\"/guide/39\"},{\"text\":\"wiki40\",\"link\":\"/guide/40\"},{\"text\":\"wiki41\",\"link\":\"/guide/41\"},{\"text\":\"wiki42\",\"link\":\"/guide/42\"},{\"text\":\"wiki43\",\"link\":\"/guide/43\"},{\"text\":\"wiki44\",\"link\":\"/guide/44\"},{\"text\":\"wiki45\",\"link\":\"/guide/45\"},{\"text\":\"wiki46\",\"link\":\"/guide/46\"},{\"text\":\"wiki47\",\"link\":\"/guide/47\"},{\"text\":\"wiki48\",\"link\":\"/guide/48\"},{\"text\":\"wiki49\",\"link\":\"/guide/49\"},{\"text\":\"wiki50\",\"link\":\"/guide/50\"},{\"text\":\"wiki51\",\"link\":\"/guide/51\"},{\"text\":\"wiki52\",\"link\":\"/guide/52\"},{\"text\":\"wiki53\",\"link\":\"/guide/53\"},{\"text\":\"wiki54\",\"link\":\"/guide/54\"},{\"text\":\"wiki55\",\"link\":\"/guide/55\"},{\"text\":\"wiki56\",\"link\":\"/guide/56\"},{\"text\":\"wiki57\",\"link\":\"/guide/57\"},{\"text\":\"wiki58\",\"link\":\"/guide/58\"},{\"text\":\"wiki59\",\"link\":\"/guide/59\"},{\"text\":\"wiki60\",\"link\":\"/guide/60\"},{\"text\":\"wiki61\",\"link\":\"/guide/61\"},{\"text\":\"wiki62\",\"link\":\"/guide/62\"},{\"text\":\"wiki63\",\"link\":\"/guide/63\"},{\"text\":\"wiki64\",\"link\":\"/guide/64\"},{\"text\":\"wiki65\",\"link\":\"/guide/65\"},{\"text\":\"wiki66\",\"link\":\"/guide/66\"},{\"text\":\"wiki67\",\"link\":\"/guide/67\"},{\"text\":\"wiki68\",\"link\":\"/guide/68\"}]},{\"text\":\"deep\",\"activeMatch\":\"^/deepseek/\",\"items\":[{\"text\":\"deep1\",\"link\":\"/deepseek/1\"},{\"text\":\"deep2\",\"link\":\"/deepseek/2\"},{\"text\":\"deep3\",\"link\":\"/deepseek/3\"},{\"text\":\"deep4\",\"link\":\"/deepseek/4\"},{\"text\":\"deep5\",\"link\":\"/deepseek/5\"},{\"text\":\"deep6\",\"link\":\"/deepseek/6\"},{\"text\":\"deep7\",\"link\":\"/deepseek/7\"},{\"text\":\"deep8\",\"link\":\"/deepseek/8\"},{\"text\":\"deep9\",\"link\":\"/deepseek/9\"},{\"text\":\"deep10\",\"link\":\"/deepseek/10\"},{\"text\":\"deep11\",\"link\":\"/deepseek/11\"},{\"text\":\"deep12\",\"link\":\"/deepseek/12\"},{\"text\":\"deep13\",\"link\":\"/deepseek/13\"},{\"text\":\"deep14\",\"link\":\"/deepseek/14\"},{\"text\":\"deep15\",\"link\":\"/deepseek/15\"},{\"text\":\"deep16\",\"link\":\"/deepseek/16\"},{\"text\":\"deep17\",\"link\":\"/deepseek/17\"},{\"text\":\"deep18\",\"link\":\"/deepseek/18\"},{\"text\":\"deep19\",\"link\":\"/deepseek/19\"},{\"text\":\"deep20\",\"link\":\"/deepseek/20\"},{\"text\":\"deep21\",\"link\":\"/deepseek/21\"},{\"text\":\"deep22\",\"link\":\"/deepseek/22\"},{\"text\":\"deep23\",\"link\":\"/deepseek/23\"},{\"text\":\"deep24\",\"link\":\"/deepseek/24\"},{\"text\":\"deep25\",\"link\":\"/deepseek/25\"},{\"text\":\"deep26\",\"link\":\"/deepseek/26\"},{\"text\":\"deep27\",\"link\":\"/deepseek/27\"},{\"text\":\"deep28\",\"link\":\"/deepseek/28\"},{\"text\":\"deep29\",\"link\":\"/deepseek/29\"},{\"text\":\"deep30\",\"link\":\"/deepseek/30\"},{\"text\":\"deep31\",\"link\":\"/deepseek/31\"},{\"text\":\"deep32\",\"link\":\"/deepseek/32\"},{\"text\":\"deep33\",\"link\":\"/deepseek/33\"},{\"text\":\"deep34\",\"link\":\"/deepseek/34\"},{\"text\":\"deep35\",\"link\":\"/deepseek/35\"},{\"text\":\"deep36\",\"link\":\"/deepseek/36\"},{\"text\":\"deep37\",\"link\":\"/deepseek/37\"},{\"text\":\"deep38\",\"link\":\"/deepseek/38\"},{\"text\":\"deep39\",\"link\":\"/deepseek/39\"},{\"text\":\"deep40\",\"link\":\"/deepseek/40\"},{\"text\":\"deep41\",\"link\":\"/deepseek/41\"},{\"text\":\"deep42\",\"link\":\"/deepseek/42\"},{\"text\":\"deep43\",\"link\":\"/deepseek/43\"},{\"text\":\"deep44\",\"link\":\"/deepseek/44\"},{\"text\":\"deep45\",\"link\":\"/deepseek/45\"},{\"text\":\"deep46\",\"link\":\"/deepseek/46\"},{\"text\":\"deep47\",\"link\":\"/deepseek/47\"},{\"text\":\"deep48\",\"link\":\"/deepseek/48\"},{\"text\":\"deep49\",\"link\":\"/deepseek/49\"},{\"text\":\"deep50\",\"link\":\"/deepseek/50\"},{\"text\":\"deep51\",\"link\":\"/deepseek/51\"},{\"text\":\"deep52\",\"link\":\"/deepseek/52\"},{\"text\":\"deep53\",\"link\":\"/deepseek/53\"},{\"text\":\"deep54\",\"link\":\"/deepseek/54\"},{\"text\":\"deep55\",\"link\":\"/deepseek/55\"},{\"text\":\"deep56\",\"link\":\"/deepseek/56\"},{\"text\":\"deep57\",\"link\":\"/deepseek/57\"},{\"text\":\"deep58\",\"link\":\"/deepseek/58\"},{\"text\":\"deep59\",\"link\":\"/deepseek/59\"},{\"text\":\"deep60\",\"link\":\"/deepseek/60\"},{\"text\":\"deep61\",\"link\":\"/deepseek/61\"},{\"text\":\"deep62\",\"link\":\"/deepseek/62\"},{\"text\":\"deep63\",\"link\":\"/deepseek/63\"},{\"text\":\"deep64\",\"link\":\"/deepseek/64\"},{\"text\":\"deep65\",\"link\":\"/deepseek/65\"},{\"text\":\"deep66\",\"link\":\"/deepseek/66\"},{\"text\":\"deep67\",\"link\":\"/deepseek/67\"},{\"text\":\"deep68\",\"link\":\"/deepseek/68\"}]},{\"text\":\"quotes\",\"activeMatch\":\"^/quotes/\",\"items\":[{\"text\":\"quotes1\",\"link\":\"/quotes/1\"},{\"text\":\"quotes2\",\"link\":\"/quotes/2\"},{\"text\":\"quotes3\",\"link\":\"/quotes/3\"},{\"text\":\"quotes4\",\"link\":\"/quotes/4\"},{\"text\":\"quotes5\",\"link\":\"/quotes/5\"},{\"text\":\"quotes6\",\"link\":\"/quotes/6\"},{\"text\":\"quotes7\",\"link\":\"/quotes/7\"},{\"text\":\"quotes8\",\"link\":\"/quotes/8\"},{\"text\":\"quotes9\",\"link\":\"/quotes/9\"},{\"text\":\"quotes10\",\"link\":\"/quotes/10\"},{\"text\":\"quotes11\",\"link\":\"/quotes/11\"},{\"text\":\"quotes12\",\"link\":\"/quotes/12\"},{\"text\":\"quotes13\",\"link\":\"/quotes/13\"},{\"text\":\"quotes14\",\"link\":\"/quotes/14\"},{\"text\":\"quotes15\",\"link\":\"/quotes/15\"},{\"text\":\"quotes16\",\"link\":\"/quotes/16\"},{\"text\":\"quotes17\",\"link\":\"/quotes/17\"},{\"text\":\"quotes18\",\"link\":\"/quotes/18\"},{\"text\":\"quotes19\",\"link\":\"/quotes/19\"},{\"text\":\"quotes20\",\"link\":\"/quotes/20\"},{\"text\":\"quotes21\",\"link\":\"/quotes/21\"},{\"text\":\"quotes22\",\"link\":\"/quotes/22\"},{\"text\":\"quotes23\",\"link\":\"/quotes/23\"},{\"text\":\"quotes24\",\"link\":\"/quotes/24\"},{\"text\":\"quotes25\",\"link\":\"/quotes/25\"},{\"text\":\"quotes26\",\"link\":\"/quotes/26\"},{\"text\":\"quotes27\",\"link\":\"/quotes/27\"},{\"text\":\"quotes28\",\"link\":\"/quotes/28\"},{\"text\":\"quotes29\",\"link\":\"/quotes/29\"},{\"text\":\"quotes30\",\"link\":\"/quotes/30\"},{\"text\":\"quotes31\",\"link\":\"/quotes/31\"},{\"text\":\"quotes32\",\"link\":\"/quotes/32\"},{\"text\":\"quotes33\",\"link\":\"/quotes/33\"},{\"text\":\"quotes34\",\"link\":\"/quotes/34\"},{\"text\":\"quotes35\",\"link\":\"/quotes/35\"},{\"text\":\"quotes36\",\"link\":\"/quotes/36\"},{\"text\":\"quotes37\",\"link\":\"/quotes/37\"},{\"text\":\"quotes38\",\"link\":\"/quotes/38\"},{\"text\":\"quotes39\",\"link\":\"/quotes/39\"},{\"text\":\"quotes40\",\"link\":\"/quotes/40\"},{\"text\":\"quotes41\",\"link\":\"/quotes/41\"},{\"text\":\"quotes42\",\"link\":\"/quotes/42\"},{\"text\":\"quotes43\",\"link\":\"/quotes/43\"},{\"text\":\"quotes44\",\"link\":\"/quotes/44\"},{\"text\":\"quotes45\",\"link\":\"/quotes/45\"},{\"text\":\"quotes46\",\"link\":\"/quotes/46\"},{\"text\":\"quotes47\",\"link\":\"/quotes/47\"},{\"text\":\"quotes48\",\"link\":\"/quotes/48\"},{\"text\":\"quotes49\",\"link\":\"/quotes/49\"},{\"text\":\"quotes50\",\"link\":\"/quotes/50\"},{\"text\":\"quotes51\",\"link\":\"/quotes/51\"},{\"text\":\"quotes52\",\"link\":\"/quotes/52\"},{\"text\":\"quotes53\",\"link\":\"/quotes/53\"},{\"text\":\"quotes54\",\"link\":\"/quotes/54\"},{\"text\":\"quotes55\",\"link\":\"/quotes/55\"},{\"text\":\"quotes56\",\"link\":\"/quotes/56\"},{\"text\":\"quotes57\",\"link\":\"/quotes/57\"},{\"text\":\"quotes58\",\"link\":\"/quotes/58\"},{\"text\":\"quotes59\",\"link\":\"/quotes/59\"},{\"text\":\"quotes60\",\"link\":\"/quotes/60\"},{\"text\":\"quotes61\",\"link\":\"/quotes/61\"},{\"text\":\"quotes62\",\"link\":\"/quotes/62\"},{\"text\":\"quotes63\",\"link\":\"/quotes/63\"},{\"text\":\"quotes64\",\"link\":\"/quotes/64\"},{\"text\":\"quotes65\",\"link\":\"/quotes/65\"},{\"text\":\"quotes66\",\"link\":\"/quotes/66\"},{\"text\":\"quotes67\",\"link\":\"/quotes/67\"},{\"text\":\"quotes68\",\"link\":\"/quotes/68\"}]},{\"text\":\"chatai\",\"activeMatch\":\"^/chatai/\",\"items\":[{\"text\":\"chatai1\",\"link\":\"/chatai/1\"},{\"text\":\"chatai2\",\"link\":\"/chatai/2\"},{\"text\":\"chatai3\",\"link\":\"/chatai/3\"},{\"text\":\"chatai4\",\"link\":\"/chatai/4\"},{\"text\":\"chatai5\",\"link\":\"/chatai/5\"},{\"text\":\"chatai6\",\"link\":\"/chatai/6\"},{\"text\":\"chatai7\",\"link\":\"/chatai/7\"},{\"text\":\"chatai8\",\"link\":\"/chatai/8\"},{\"text\":\"chatai9\",\"link\":\"/chatai/9\"},{\"text\":\"chatai10\",\"link\":\"/chatai/10\"},{\"text\":\"chatai11\",\"link\":\"/chatai/11\"},{\"text\":\"chatai12\",\"link\":\"/chatai/12\"},{\"text\":\"chatai13\",\"link\":\"/chatai/13\"},{\"text\":\"chatai14\",\"link\":\"/chatai/14\"},{\"text\":\"chatai15\",\"link\":\"/chatai/15\"},{\"text\":\"chatai16\",\"link\":\"/chatai/16\"},{\"text\":\"chatai17\",\"link\":\"/chatai/17\"},{\"text\":\"chatai18\",\"link\":\"/chatai/18\"},{\"text\":\"chatai19\",\"link\":\"/chatai/19\"},{\"text\":\"chatai20\",\"link\":\"/chatai/20\"},{\"text\":\"chatai21\",\"link\":\"/chatai/21\"},{\"text\":\"chatai22\",\"link\":\"/chatai/22\"},{\"text\":\"chatai23\",\"link\":\"/chatai/23\"},{\"text\":\"chatai24\",\"link\":\"/chatai/24\"},{\"text\":\"chatai25\",\"link\":\"/chatai/25\"},{\"text\":\"chatai26\",\"link\":\"/chatai/26\"},{\"text\":\"chatai27\",\"link\":\"/chatai/27\"},{\"text\":\"chatai28\",\"link\":\"/chatai/28\"},{\"text\":\"chatai29\",\"link\":\"/chatai/29\"},{\"text\":\"chatai30\",\"link\":\"/chatai/30\"},{\"text\":\"chatai31\",\"link\":\"/chatai/31\"},{\"text\":\"chatai32\",\"link\":\"/chatai/32\"},{\"text\":\"chatai33\",\"link\":\"/chatai/33\"},{\"text\":\"chatai34\",\"link\":\"/chatai/34\"},{\"text\":\"chatai35\",\"link\":\"/chatai/35\"},{\"text\":\"chatai36\",\"link\":\"/chatai/36\"},{\"text\":\"chatai37\",\"link\":\"/chatai/37\"},{\"text\":\"chatai38\",\"link\":\"/chatai/38\"},{\"text\":\"chatai39\",\"link\":\"/chatai/39\"},{\"text\":\"chatai40\",\"link\":\"/chatai/40\"},{\"text\":\"chatai41\",\"link\":\"/chatai/41\"},{\"text\":\"chatai42\",\"link\":\"/chatai/42\"},{\"text\":\"chatai43\",\"link\":\"/chatai/43\"},{\"text\":\"chatai44\",\"link\":\"/chatai/44\"},{\"text\":\"chatai45\",\"link\":\"/chatai/45\"},{\"text\":\"chatai46\",\"link\":\"/chatai/46\"},{\"text\":\"chatai47\",\"link\":\"/chatai/47\"},{\"text\":\"chatai48\",\"link\":\"/chatai/48\"},{\"text\":\"chatai49\",\"link\":\"/chatai/49\"},{\"text\":\"chatai50\",\"link\":\"/chatai/50\"},{\"text\":\"chatai51\",\"link\":\"/chatai/51\"},{\"text\":\"chatai52\",\"link\":\"/chatai/52\"},{\"text\":\"chatai53\",\"link\":\"/chatai/53\"},{\"text\":\"chatai54\",\"link\":\"/chatai/54\"},{\"text\":\"chatai55\",\"link\":\"/chatai/55\"},{\"text\":\"chatai56\",\"link\":\"/chatai/56\"},{\"text\":\"chatai57\",\"link\":\"/chatai/57\"},{\"text\":\"chatai58\",\"link\":\"/chatai/58\"},{\"text\":\"chatai59\",\"link\":\"/chatai/59\"},{\"text\":\"chatai60\",\"link\":\"/chatai/60\"},{\"text\":\"chatai61\",\"link\":\"/chatai/61\"},{\"text\":\"chatai62\",\"link\":\"/chatai/62\"},{\"text\":\"chatai63\",\"link\":\"/chatai/63\"},{\"text\":\"chatai64\",\"link\":\"/chatai/64\"},{\"text\":\"chatai65\",\"link\":\"/chatai/65\"},{\"text\":\"chatai66\",\"link\":\"/chatai/66\"},{\"text\":\"chatai67\",\"link\":\"/chatai/67\"},{\"text\":\"chatai68\",\"link\":\"/chatai/68\"}]},{\"text\":\"library\",\"activeMatch\":\"^/library/\",\"items\":[{\"text\":\"library1\",\"link\":\"/library/1\"},{\"text\":\"library2\",\"link\":\"/library/2\"},{\"text\":\"library3\",\"link\":\"/library/3\"},{\"text\":\"library4\",\"link\":\"/library/4\"},{\"text\":\"library5\",\"link\":\"/library/5\"},{\"text\":\"library6\",\"link\":\"/library/6\"},{\"text\":\"library7\",\"link\":\"/library/7\"},{\"text\":\"library8\",\"link\":\"/library/8\"},{\"text\":\"library9\",\"link\":\"/library/9\"},{\"text\":\"library10\",\"link\":\"/library/10\"},{\"text\":\"library11\",\"link\":\"/library/11\"},{\"text\":\"library12\",\"link\":\"/library/12\"},{\"text\":\"library13\",\"link\":\"/library/13\"},{\"text\":\"library14\",\"link\":\"/library/14\"},{\"text\":\"library15\",\"link\":\"/library/15\"},{\"text\":\"library16\",\"link\":\"/library/16\"},{\"text\":\"library17\",\"link\":\"/library/17\"},{\"text\":\"library18\",\"link\":\"/library/18\"},{\"text\":\"library19\",\"link\":\"/library/19\"},{\"text\":\"library20\",\"link\":\"/library/20\"},{\"text\":\"library21\",\"link\":\"/library/21\"},{\"text\":\"library22\",\"link\":\"/library/22\"},{\"text\":\"library23\",\"link\":\"/library/23\"},{\"text\":\"library24\",\"link\":\"/library/24\"},{\"text\":\"library25\",\"link\":\"/library/25\"},{\"text\":\"library26\",\"link\":\"/library/26\"},{\"text\":\"library27\",\"link\":\"/library/27\"},{\"text\":\"library28\",\"link\":\"/library/28\"},{\"text\":\"library29\",\"link\":\"/library/29\"},{\"text\":\"library30\",\"link\":\"/library/30\"},{\"text\":\"library31\",\"link\":\"/library/31\"},{\"text\":\"library32\",\"link\":\"/library/32\"},{\"text\":\"library33\",\"link\":\"/library/33\"},{\"text\":\"library34\",\"link\":\"/library/34\"},{\"text\":\"library35\",\"link\":\"/library/35\"},{\"text\":\"library36\",\"link\":\"/library/36\"},{\"text\":\"library37\",\"link\":\"/library/37\"},{\"text\":\"library38\",\"link\":\"/library/38\"},{\"text\":\"library39\",\"link\":\"/library/39\"},{\"text\":\"library40\",\"link\":\"/library/40\"},{\"text\":\"library41\",\"link\":\"/library/41\"},{\"text\":\"library42\",\"link\":\"/library/42\"},{\"text\":\"library43\",\"link\":\"/library/43\"},{\"text\":\"library44\",\"link\":\"/library/44\"},{\"text\":\"library45\",\"link\":\"/library/45\"},{\"text\":\"library46\",\"link\":\"/library/46\"},{\"text\":\"library47\",\"link\":\"/library/47\"},{\"text\":\"library48\",\"link\":\"/library/48\"},{\"text\":\"library49\",\"link\":\"/library/49\"},{\"text\":\"library50\",\"link\":\"/library/50\"},{\"text\":\"library51\",\"link\":\"/library/51\"},{\"text\":\"library52\",\"link\":\"/library/52\"},{\"text\":\"library53\",\"link\":\"/library/53\"},{\"text\":\"library54\",\"link\":\"/library/54\"},{\"text\":\"library55\",\"link\":\"/library/55\"},{\"text\":\"library56\",\"link\":\"/library/56\"},{\"text\":\"library57\",\"link\":\"/library/57\"},{\"text\":\"library58\",\"link\":\"/library/58\"},{\"text\":\"library59\",\"link\":\"/library/59\"},{\"text\":\"library60\",\"link\":\"/library/60\"},{\"text\":\"library61\",\"link\":\"/library/61\"},{\"text\":\"library62\",\"link\":\"/library/62\"},{\"text\":\"library63\",\"link\":\"/library/63\"},{\"text\":\"library64\",\"link\":\"/library/64\"},{\"text\":\"library65\",\"link\":\"/library/65\"},{\"text\":\"library66\",\"link\":\"/library/66\"},{\"text\":\"library67\",\"link\":\"/library/67\"},{\"text\":\"library68\",\"link\":\"/library/68\"}]},{\"text\":\"ecosystem\",\"activeMatch\":\"^/ecosystem/\",\"items\":[{\"text\":\"website\",\"items\":[{\"text\":\"partners\",\"link\":\"/partners/\"},{\"text\":\"website\",\"link\":\"/ecosystem/themes\"},{\"text\":\"deepseekletters\",\"link\":\"/ecosystem/newsletters\"},{\"text\":\"AI Navigation\",\"link\":\"/ecosystem/navigation\"},{\"text\":\"DeepSeek-V3\",\"link\":\"/ecosystem/DeepSeek\"},{\"text\":\"474x.com\",\"link\":\"https://www.474x.com\"},{\"text\":\"494x.com\",\"link\":\"https://www.494x.com\"},{\"text\":\"64ii.com\",\"link\":\"https://www.64ii.com\"},{\"text\":\"81oo.com\",\"link\":\"https://www.81oo.com\"}]},{\"text\":\"Library\",\"items\":[{\"text\":\"Vue Router\",\"link\":\"https://e.m44m.com/\"},{\"text\":\"Pinia\",\"link\":\"https://f.m44m.com/\"},{\"text\":\"tool\",\"link\":\"https://www.82ii.com\"}]},{\"text\":\"Vue\",\"items\":[{\"text\":\"Vue Mastery\",\"link\":\"https://g.m44m.com\"},{\"text\":\"Vue School\",\"link\":\"https://h.m44m.com\"}]},{\"text\":\"help\",\"items\":[{\"text\":\"Discord\",\"link\":\"https://i.m44m.com\"},{\"text\":\"GitHub\",\"link\":\"https://github.com/hyaliyun/DeepMind\"},{\"text\":\"DEV\",\"link\":\"https://www.z2.pw\"}]},{\"text\":\"DeepMind\",\"items\":[{\"text\":\"blog\",\"link\":\"https://c.m44m.com\"},{\"text\":\"Twitter\",\"link\":\"https://d.m44m.com\"},{\"text\":\"Activity\",\"link\":\"https://e.m44m.com\"},{\"text\":\"CMS\",\"link\":\"https://w.z2.pw\"},{\"text\":\"deepseekmagSheets\",\"link\":\"https://a.z2.pw\"},{\"text\":\"Tailwind\",\"link\":\"https://a.434x.com\"},{\"text\":\"Three.js\",\"link\":\"https://b.434x.com\"},{\"text\":\"youtube\",\"link\":\"https://www.q8q9.com\"}]}]},{\"text\":\"team\",\"link\":\"/about/team\",\"activeMatch\":\"^/about/\"},{\"text\":\"show\",\"activeMatch\":\"^/(guide|style-guide|cookbook|examples)/\",\"items\":[{\"text\":\"donation\",\"link\":\"/drive/donation\"},{\"text\":\"PromptLibrary\",\"link\":\"/drive/PromptLibrary\"},{\"text\":\"prompt\",\"link\":\"/drive/prompt\"},{\"text\":\"crypto\",\"link\":\"/drive/team\"},{\"text\":\"partners\",\"link\":\"/partners/\"},{\"text\":\"3kk3.com\",\"link\":\"https://www.3kk3.com\"},{\"text\":\"deepseek\",\"link\":\"https://b.q8q9.com\"},{\"text\":\"deepseekr1\",\"link\":\"https://c.4s5s.com\"},{\"text\":\"deepseekr2\",\"link\":\"https://b.6n7n.com\"},{\"text\":\"deepseekr3\",\"link\":\"https://f.m44m.com\"},{\"text\":\"deepseekr4\",\"link\":\"https://c.q8q9.com\"},{\"text\":\"deepseekr5\",\"link\":\"https://a.l00m.com\"},{\"text\":\"deepseekr6\",\"link\":\"https://g.m44m.com\"}]},{\"text\":\"swap\",\"link\":\"/swap/app\",\"activeMatch\":\"^/swap/\"}],\"sidebar\":{},\"localeLinks\":[{\"link\":\"https://g.m44m.com\",\"text\":\"简体中文\",\"repo\":\"https://github.com/hyaliyun/DeepMind\"}],\"algolia\":{\"indexName\":\"DeepMind\",\"appId\":\"ML0LEBN7FQ\",\"Key\":\"21cf9df0734770a2448a9da64a700c22\",\"searchParameters\":{\"facetFilters\":[\"version:v3\"]}},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/hyaliyun/DeepMind/\"}],\"editLink\":{\"repo\":\"hyaliyun/DeepMind\",\"text\":\"Edit this page on GitHub\"},\"footer\":{\"license\":{\"text\":\"DeepMind License\",\"link\":\"https://www.m44m.com\"},\"copyright\":\"Copyright © 2014-2025 DeepMind\"}},\"locales\":{},\"scrollOffset\":[\"header\",\".VPLocalNav\"],\"cleanUrls\":false}");</script>
    
  </body>
</html>